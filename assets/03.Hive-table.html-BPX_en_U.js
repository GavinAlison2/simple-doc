import{_ as n,c as a,d as e,o as p}from"./app-DFjXMARq.js";const l="/simple-doc/assets/bucket-DW0zdDHl.png",i="/simple-doc/assets/hive-ctas-_Ksk0dUn.png",t="/simple-doc/assets/hive-bucket-res-BnXeA_7x.png",c={};function o(d,s){return p(),a("div",null,s[0]||(s[0]=[e(`<h1 id="hive-分区表和分桶表" tabindex="-1"><a class="header-anchor" href="#hive-分区表和分桶表"><span>Hive 分区表和分桶表</span></a></h1><h2 id="一、分区表" tabindex="-1"><a class="header-anchor" href="#一、分区表"><span>一、分区表</span></a></h2><h3 id="概念" tabindex="-1"><a class="header-anchor" href="#概念"><span>概念</span></a></h3><p>Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。</p><p><strong>分区为 HDFS 上表目录的子目录</strong>，数据按照分区存储在子目录中。如果查询的 <code>where</code> 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。</p><blockquote><p>这里说明一下分区表并非 Hive 独有的概念，实际上这个概念非常常见。比如在我们常用的 Oracle 数据库中，当表中的数据量不断增大，查询数据的速度就会下降，这时也可以对表进行分区。表进行分区后，逻辑上表仍然是一张完整的表，只是将表中的数据存放到多个表空间（物理文件上），这样查询数据时，就不必要每次都扫描整张表，从而提升查询性能。</p></blockquote><h3 id="使用场景" tabindex="-1"><a class="header-anchor" href="#使用场景"><span>使用场景</span></a></h3><p>通常，在管理大规模数据集的时候都需要进行分区，比如将日志文件按天进行分区，从而保证数据细粒度的划分，使得查询性能得到提升。</p><h3 id="创建分区表" tabindex="-1"><a class="header-anchor" href="#创建分区表"><span>创建分区表</span></a></h3><p>在 Hive 中可以使用 <code>PARTITIONED BY</code> 子句创建分区表。表可以包含一个或多个分区列，程序会为分区列中的每个不同值组合创建单独的数据目录。下面的我们创建一张雇员表作为测试：</p><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line"> <span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> emp_partition<span class="token punctuation">(</span></span>
<span class="line">    empno <span class="token keyword">INT</span><span class="token punctuation">,</span></span>
<span class="line">    ename STRING<span class="token punctuation">,</span></span>
<span class="line">    job STRING<span class="token punctuation">,</span></span>
<span class="line">    mgr <span class="token keyword">INT</span><span class="token punctuation">,</span></span>
<span class="line">    hiredate <span class="token keyword">TIMESTAMP</span><span class="token punctuation">,</span></span>
<span class="line">    sal <span class="token keyword">DECIMAL</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    comm <span class="token keyword">DECIMAL</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">)</span></span>
<span class="line">    PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>deptno <span class="token keyword">INT</span><span class="token punctuation">)</span>   <span class="token comment">-- 按照部门编号进行分区</span></span>
<span class="line">    <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">&quot;\\t&quot;</span></span>
<span class="line">    LOCATION <span class="token string">&#39;/hive/emp_partition&#39;</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="加载数据到分区表" tabindex="-1"><a class="header-anchor" href="#加载数据到分区表"><span>加载数据到分区表</span></a></h3><p>加载数据到分区表时候必须要指定数据所处的分区：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># 加载部门编号为20的数据到表中</span></span>
<span class="line">LOAD DATA LOCAL INPATH <span class="token string">&quot;/usr/file/emp20.txt&quot;</span> OVERWRITE INTO TABLE emp_partition PARTITION <span class="token punctuation">(</span>deptno<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 加载部门编号为30的数据到表中</span></span>
<span class="line">LOAD DATA LOCAL INPATH <span class="token string">&quot;/usr/file/emp30.txt&quot;</span> OVERWRITE INTO TABLE emp_partition PARTITION <span class="token punctuation">(</span>deptno<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="查看分区目录" tabindex="-1"><a class="header-anchor" href="#查看分区目录"><span>查看分区目录</span></a></h3><p>这时候我们直接查看表目录，可以看到表目录下存在两个子目录，分别是 <code>deptno=20</code> 和 <code>deptno=30</code>,这就是分区目录，分区目录下才是我们加载的数据文件。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># hadoop fs -ls  hdfs://hadoop001:8020/hive/emp_partition/</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这时候当你的查询语句的 <code>where</code> 包含 <code>deptno=20</code>，则就去对应的分区目录下进行查找，而不用扫描全表。</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">hdfs://hadoop001:8020/hive/emp_partition/deptno=20/</span>
<span class="line">hdfs://hadoop001:8020/hive/emp_partition/deptno=30/ </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="二、分桶表" tabindex="-1"><a class="header-anchor" href="#二、分桶表"><span>二、分桶表</span></a></h2><h3 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h3><p>分区提供了一个隔离数据和优化查询的可行方案，但是并非所有的数据集都可以形成合理的分区，分区的数量也不是越多越好，过多的分区条件可能会导致很多分区上没有数据。同时 Hive 会限制动态分区可以创建的最大分区数，用来避免过多分区文件对文件系统产生负担。鉴于以上原因，Hive 还提供了一种更加细粒度的数据拆分方案：分桶表 (bucket Table)。</p><p>分桶表会将指定列的值进行哈希散列，并对 bucket（桶数量）取余，然后存储到对应的 bucket（桶）中。</p><h3 id="理解分桶表" tabindex="-1"><a class="header-anchor" href="#理解分桶表"><span>理解分桶表</span></a></h3><p>单从概念上理解分桶表可能会比较晦涩，其实和分区一样，分桶这个概念同样不是 Hive 独有的，对于 Java 开发人员而言，这可能是一个每天都会用到的概念，因为 Hive 中的分桶概念和 Java 数据结构中的 HashMap 的分桶概念是一致的。</p><p>当调用 HashMap 的 put() 方法存储数据时，程序会先对 key 值调用 hashCode() 方法计算出 hashcode，然后对数组长度取模计算出 index，最后将数据存储在数组 index 位置的链表上，链表达到一定阈值后会转换为红黑树 (JDK1.8+)。下图为 HashMap 的数据结构图：</p><p><img src="`+l+`" alt="bucket"></p><p>图片引用自：[HashMap vs. Hashtable]</p><h3 id="创建分桶表" tabindex="-1"><a class="header-anchor" href="#创建分桶表"><span>创建分桶表</span></a></h3><p>在 Hive 中，我们可以通过 <code>CLUSTERED BY</code> 指定分桶列，并通过 <code>SORTED BY</code> 指定桶中数据的排序参考列。下面为分桶表建表语句示例：</p><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line">  <span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> emp_bucket<span class="token punctuation">(</span></span>
<span class="line">    empno <span class="token keyword">INT</span><span class="token punctuation">,</span></span>
<span class="line">    ename STRING<span class="token punctuation">,</span></span>
<span class="line">    job STRING<span class="token punctuation">,</span></span>
<span class="line">    mgr <span class="token keyword">INT</span><span class="token punctuation">,</span></span>
<span class="line">    hiredate <span class="token keyword">TIMESTAMP</span><span class="token punctuation">,</span></span>
<span class="line">    sal <span class="token keyword">DECIMAL</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    comm <span class="token keyword">DECIMAL</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    deptno <span class="token keyword">INT</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span><span class="token punctuation">(</span>empno<span class="token punctuation">)</span> SORTED <span class="token keyword">BY</span><span class="token punctuation">(</span>empno <span class="token keyword">ASC</span><span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">4</span> BUCKETS  <span class="token comment">--按照员工编号散列到四个 bucket 中</span></span>
<span class="line">    <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">&quot;\\t&quot;</span></span>
<span class="line">    LOCATION <span class="token string">&#39;/hive/emp_bucket&#39;</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="加载数据到分桶表" tabindex="-1"><a class="header-anchor" href="#加载数据到分桶表"><span>加载数据到分桶表</span></a></h3><p>这里直接使用 <code>Load</code> 语句向分桶表加载数据，数据时可以加载成功的，但是数据并不会分桶。</p><p>这是由于分桶的实质是对指定字段做了 hash 散列然后存放到对应文件中，这意味着向分桶表中插入数据是必然要通过 MapReduce，且 Reducer 的数量必须等于分桶的数量。由于以上原因，分桶表的数据通常只能使用 CTAS(CREATE TABLE AS SELECT) 方式插入，因为 CTAS 操作会触发 MapReduce。加载数据步骤如下：</p><h4 id="设置强制分桶" tabindex="-1"><a class="header-anchor" href="#设置强制分桶"><span>设置强制分桶</span></a></h4><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--Hive 2.x 不需要这一步</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>在 Hive 0.x and 1.x 版本，必须使用设置 <code>hive.enforce.bucketing = true</code>，表示强制分桶，允许程序根据表结构自动选择正确数量的 Reducer 和 cluster by column 来进行分桶。</p><h4 id="ctas-导入数据" tabindex="-1"><a class="header-anchor" href="#ctas-导入数据"><span>CTAS 导入数据</span></a></h4><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> emp_bucket <span class="token keyword">SELECT</span> <span class="token operator">*</span>  <span class="token keyword">FROM</span> emp<span class="token punctuation">;</span>  <span class="token comment">--这里的 emp 表就是一张普通的雇员表</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>可以从执行日志看到 CTAS 触发 MapReduce 操作，且 Reducer 数量和建表时候指定 bucket 数量一致：</p><p><img src="`+i+'" alt="ctas"></p><h3 id="查看分桶文件" tabindex="-1"><a class="header-anchor" href="#查看分桶文件"><span>查看分桶文件</span></a></h3><p>bucket(桶) 本质上就是表目录下的具体文件：</p><p><img src="'+t+`" alt="bucket-files"></p><h2 id="三、分区表和分桶表结合使用" tabindex="-1"><a class="header-anchor" href="#三、分区表和分桶表结合使用"><span>三、分区表和分桶表结合使用</span></a></h2><p>分区表和分桶表的本质都是将数据按照不同粒度进行拆分，从而使得在查询时候不必扫描全表，只需要扫描对应的分区或分桶，从而提升查询效率。两者可以结合起来使用，从而保证表数据在不同粒度上都能得到合理的拆分。下面是 Hive 官方给出的示例：</p><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> page_view_bucketed<span class="token punctuation">(</span></span>
<span class="line">	viewTime <span class="token keyword">INT</span><span class="token punctuation">,</span></span>
<span class="line">    userid <span class="token keyword">BIGINT</span><span class="token punctuation">,</span></span>
<span class="line">    page_url STRING<span class="token punctuation">,</span></span>
<span class="line">    referrer_url STRING<span class="token punctuation">,</span></span>
<span class="line">    ip STRING <span class="token punctuation">)</span></span>
<span class="line"> PARTITIONED <span class="token keyword">BY</span><span class="token punctuation">(</span>dt STRING<span class="token punctuation">)</span></span>
<span class="line"> <span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span><span class="token punctuation">(</span>userid<span class="token punctuation">)</span> SORTED <span class="token keyword">BY</span><span class="token punctuation">(</span>viewTime<span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">32</span> BUCKETS</span>
<span class="line"> <span class="token keyword">ROW</span> FORMAT DELIMITED</span>
<span class="line">   <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">&#39;\\001&#39;</span></span>
<span class="line">   COLLECTION ITEMS <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">&#39;\\002&#39;</span></span>
<span class="line">   MAP <span class="token keyword">KEYS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">&#39;\\003&#39;</span></span>
<span class="line"> STORED <span class="token keyword">AS</span> SEQUENCEFILE<span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>此时导入数据时需要指定分区：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">INSERT OVERWRITE page_view_bucketed</span>
<span class="line">PARTITION <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">&#39;2009-02-25&#39;</span><span class="token punctuation">)</span></span>
<span class="line">SELECT * FROM page_view WHERE <span class="token assign-left variable">dt</span><span class="token operator">=</span><span class="token string">&#39;2009-02-25&#39;</span><span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="笔记" tabindex="-1"><a class="header-anchor" href="#笔记"><span>笔记</span></a></h2><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">use test;</span>
<span class="line">show tables;</span>
<span class="line">show create table emp_partition;</span>
<span class="line"></span>
<span class="line">select * from emp where deptno = 20 ;</span>
<span class="line"></span>
<span class="line">INSERT OVERWRITE LOCAL DIRECTORY &#39;/tmp/emp-20&#39;</span>
<span class="line">ROW FORMAT DELIMITED</span>
<span class="line">FIELDS TERMINATED BY &#39;,&#39;</span>
<span class="line">SELECT * FROM emp where deptno = 20 ;</span>
<span class="line"></span>
<span class="line">INSERT OVERWRITE LOCAL DIRECTORY &#39;/tmp/emp-30&#39;</span>
<span class="line">ROW FORMAT DELIMITED</span>
<span class="line">FIELDS TERMINATED BY &#39;,&#39;</span>
<span class="line">SELECT * FROM emp where deptno = 30 ;</span>
<span class="line"></span>
<span class="line">-- cat /tmp/emp-20/*   &gt; /tmp/emp-20.csv</span>
<span class="line">-- cat /tmp/emp-30/*   &gt; /tmp/emp-30.csv</span>
<span class="line">-- rm -rf /tmp/emp-20 /tmp/emp-30</span>
<span class="line"></span>
<span class="line">LOAD DATA LOCAL INPATH &quot;/tmp/emp-20.csv&quot; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=20);</span>
<span class="line"></span>
<span class="line">LOAD DATA LOCAL INPATH &quot;/tmp/emp-30.csv&quot; OVERWRITE INTO TABLE emp_partition PARTITION (deptno=30);</span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables" target="_blank" rel="noopener noreferrer">LanguageManual DDL BucketedTables</a></li></ul>`,53)]))}const u=n(c,[["render",o]]),k=JSON.parse('{"path":"/guide/etl/hive/03.Hive-table.html","title":"Hive 分区表和分桶表","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"一、分区表","slug":"一、分区表","link":"#一、分区表","children":[{"level":3,"title":"概念","slug":"概念","link":"#概念","children":[]},{"level":3,"title":"使用场景","slug":"使用场景","link":"#使用场景","children":[]},{"level":3,"title":"创建分区表","slug":"创建分区表","link":"#创建分区表","children":[]},{"level":3,"title":"加载数据到分区表","slug":"加载数据到分区表","link":"#加载数据到分区表","children":[]},{"level":3,"title":"查看分区目录","slug":"查看分区目录","link":"#查看分区目录","children":[]}]},{"level":2,"title":"二、分桶表","slug":"二、分桶表","link":"#二、分桶表","children":[{"level":3,"title":"简介","slug":"简介","link":"#简介","children":[]},{"level":3,"title":"理解分桶表","slug":"理解分桶表","link":"#理解分桶表","children":[]},{"level":3,"title":"创建分桶表","slug":"创建分桶表","link":"#创建分桶表","children":[]},{"level":3,"title":"加载数据到分桶表","slug":"加载数据到分桶表","link":"#加载数据到分桶表","children":[]},{"level":3,"title":"查看分桶文件","slug":"查看分桶文件","link":"#查看分桶文件","children":[]}]},{"level":2,"title":"三、分区表和分桶表结合使用","slug":"三、分区表和分桶表结合使用","link":"#三、分区表和分桶表结合使用","children":[]},{"level":2,"title":"笔记","slug":"笔记","link":"#笔记","children":[]},{"level":2,"title":"参考资料","slug":"参考资料","link":"#参考资料","children":[]}],"git":{"updatedTime":1744649093000,"contributors":[{"name":"alice","username":"alice","email":"921757697@qq.com","commits":1,"url":"https://github.com/alice"}],"changelog":[{"hash":"dbc8fce7f951c4a919f1b3e3e4548a92c08bdeba","time":1744649093000,"email":"921757697@qq.com","author":"alice","message":"deploy"}]},"filePathRelative":"guide/etl/hive/03.Hive-table.md"}');export{u as comp,k as data};
