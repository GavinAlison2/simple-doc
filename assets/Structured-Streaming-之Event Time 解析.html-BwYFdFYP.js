import{_ as t,c as o,e as n,a as i,d as a,b as p,w as c,r as l,o as r}from"./app-DlGl6QFf.js";const d="/simple-doc/assets/20250420013-CKEx0ltu.png",m="/simple-doc/assets/20250420014-DOw9siDy.png",u="/simple-doc/assets/20250420015-Bcott2uV.png",g="/simple-doc/assets/20250420016-BTGD6A0H.png",h="/simple-doc/assets/20250420017-six01BTB.png",k="/simple-doc/assets/20250420018-DIieF1H-.png",v={};function w(b,e){const s=l("RouteLink");return r(),o("div",null,[e[3]||(e[3]=n(`<h1 id="structured-streaming-之-event-time-解析" tabindex="-1"><a class="header-anchor" href="#structured-streaming-之-event-time-解析"><span>Structured Streaming 之 Event Time 解析</span></a></h1><p><em><strong>[酷玩 Spark] Structured Streaming 源码解析系列</strong></em></p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">本文内容适用范围：</span>
<span class="line">* 2018.11.02 update, Spark 2.4 全系列 √ (已发布：2.4.0)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div>`,3)),i("p",null,[e[1]||(e[1]=a("阅读本文前，请一定先阅读 ")),p(s,{to:"/guide/etl/spark/Structured%20Streaming%20%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E7%8E%B0%E6%A6%82%E8%BF%B0%20.html"},{default:c(()=>e[0]||(e[0]=[a("Structured Streaming 实现思路与实现概述")])),_:1}),e[2]||(e[2]=a(" 一文，其中概述了 Structured Streaming 的实现思路，有了全局概念后再看本文的细节解释。"))]),e[4]||(e[4]=n(`<h2 id="event-time" tabindex="-1"><a class="header-anchor" href="#event-time"><span>Event Time !</span></a></h2><p>Spark Streaming 时代有过非官方的 event time 支持尝试 [1]，而在进化后的 Structured Streaming 里，添加了对 event time 的原生支持。</p><p>我们来看一段官方 programming guide 的例子 [2]：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</span>
<span class="line"></span>
<span class="line"><span class="token keyword">val</span> words <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment">// streaming DataFrame of schema { timestamp: Timestamp, word: String }</span></span>
<span class="line"></span>
<span class="line"><span class="token comment">// Group the data by window and word and compute the count of each group</span></span>
<span class="line"><span class="token comment">// Please note: we&#39;ll revise this example in &lt;Structured Streaming 之 Watermark 解析&gt;</span></span>
<span class="line"><span class="token keyword">val</span> windowedCounts <span class="token operator">=</span> words<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span></span>
<span class="line">  window<span class="token punctuation">(</span>$<span class="token string">&quot;timestamp&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;10 minutes&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;5 minutes&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">  $<span class="token string">&quot;word&quot;</span></span>
<span class="line"><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里的执行过程如下图。</p><p align="center"><img src="`+d+'"></p><ul><li>我们有一系列 arriving 的 records</li><li>首先是一个对着时间列 <code>timestamp</code> 做长度为<code>10m</code>，滑动为<code>5m</code> 的 <em>window()</em> 操作 <ul><li>例如上图右上角的虚框部分，当达到一条记录 <code>12:22|dog</code> 时，会将 <code>12:22</code> 归入两个窗口 <code>12:15-12:25</code>、<code>12:20-12:30</code>，所以产生两条记录：<code>12:15-12:25|dog</code>、<code>12:20-12:30|dog</code>，对于记录 <code>12:24|dog owl</code> 同理产生两条记录：<code>12:15-12:25|dog owl</code>、<code>12:20-12:30|dog owl</code></li><li>所以这里 <em>window()</em> 操作的本质是 <em>explode()</em>，可由一条数据产生多条数据</li></ul></li><li>然后对 <em>window()</em> 操作的结果，以 <code>window</code> 列和 <code>word</code> 列为 key，做 <em>groupBy().count()</em> 操作 <ul><li>这个操作的聚合过程是增量的（借助 StateStore）</li></ul></li><li>最后得到一个有 <code>window</code>, <code>word</code>, <code>count</code> 三列的状态集</li></ul><h2 id="处理-late-data" tabindex="-1"><a class="header-anchor" href="#处理-late-data"><span>处理 Late Data</span></a></h2><p>还是沿用前面 <em>window()</em> + <em>groupBy().count()</em> 的例子，但注意有一条迟到的数据 <code>12:06|cat</code> ：</p><p align="center"><img src="'+m+'"></p><p>可以看到，在这里的 late data，在 State 里被正确地更新到了应在的位置。</p><h2 id="outputmodes" tabindex="-1"><a class="header-anchor" href="#outputmodes"><span>OutputModes</span></a></h2><p>我们继续来看前面 <em>window()</em> + <em>groupBy().count()</em> 的例子，现在我们考虑将结果输出，即考虑 OutputModes：</p><h4 id="a-complete" tabindex="-1"><a class="header-anchor" href="#a-complete"><span>(a) Complete</span></a></h4><p>Complete 的输出是和 State 是完全一致的：</p><p align="center"><img src="'+u+'"></p><h4 id="b-append" tabindex="-1"><a class="header-anchor" href="#b-append"><span>(b) Append</span></a></h4><p>Append 的语义将保证，一旦输出了某条 key，未来就不会再输出同一个 key。</p><p align="center"><img src="'+g+'"></p><p>所以，在上图 <code>12:10</code> 这个批次直接输出 <code>12:00-12:10|cat|1</code>, <code>12:05-12:15|cat|1</code> 将是错误的，因为在 <code>12:20</code> 将结果更新为了 <code>12:00-12:10|cat|2</code>，但是 Append 模式下却不会再次输出 <code>12:00-12:10|cat|2</code>，因为前面输出过了同一条 key <code>12:00-12:10|cat</code> 的结果<code>12:00-12:10|cat|1</code>。</p><p>为了解决这个问题，在 Append 模式下，Structured Streaming 需要知道，某一条 key 的结果什么时候不会再更新了。当确认结果不会再更新的时候（下一篇文章专门详解依靠 watermark 确认结果不再更新），就可以将结果进行输出。</p><p align="center"><img src="'+h+'"></p><p>如上图所示，如果我们确定 <code>12:30</code> 这个批次以后不会再有对 <code>12:00-12:10</code> 这个 window 的更新，那么我们就可以把 <code>12:00-12:10</code> 的结果在 <code>12:30</code> 这个批次输出，并且也会保证后面的批次不会再输出 <code>12:00-12:10</code> 的 window 的结果，维护了 Append 模式的语义。</p><h4 id="c-update" tabindex="-1"><a class="header-anchor" href="#c-update"><span>(c) Update</span></a></h4><p>Update 模式已在 Spark 2.1.1 及以后版本获得正式支持。</p><p align="center"><img src="'+k+'"></p><p>如上图所示，在 Update 模式中，只有本执行批次 State 中被更新了的条目会被输出：</p><ul><li>在 12:10 这个执行批次，State 中全部 2 条都是新增的（因而也都是被更新了的），所以输出全部 2 条；</li><li>在 12:20 这个执行批次，State 中 2 条是被更新了的、 4 条都是新增的（因而也都是被更新了的），所以输出全部 6 条；</li><li>在 12:30 这个执行批次，State 中 4 条是被更新了的，所以输出 4 条。这些需要特别注意的一点是，如 Append 模式一样，本执行批次中由于（通过 watermark 机制）确认 <code>12:00-12:10</code> 这个 window 不会再被更新，因而将其从 State 中去除，但没有因此产生输出。</li></ul><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>本文解析了 Structured Streaming 原生提供的对 event time 的支持，包括 window()、groupBy() 增量聚合、对 late date 的支持、以及在 Complete, Append, Update 模式下的输出结果。</p><h2 id="扩展阅读" tabindex="-1"><a class="header-anchor" href="#扩展阅读"><span>扩展阅读</span></a></h2><ol><li><a href="https://github.com/apache/spark/blob/v2.1.1/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L2232" target="_blank" rel="noopener noreferrer">Github: org/apache/spark/sql/catalyst/analysis/Analyzer.scala#TimeWindowing</a></li><li><a href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/TimeWindow.scala" target="_blank" rel="noopener noreferrer">Github: org/apache/spark/sql/catalyst/expressions/TimeWindow</a></li></ol><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ol><li>https://github.com/cloudera/spark-dataflow</li><li><a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time" target="_blank" rel="noopener noreferrer">Structured Streaming Programming Guide - Window Operations on Event Time</a></li></ol><br>',35))])}const f=t(v,[["render",w]]),E=JSON.parse('{"path":"/guide/etl/spark/Structured-Streaming-%E4%B9%8BEvent%20Time%20%E8%A7%A3%E6%9E%90.html","title":"Structured Streaming 之 Event Time 解析","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"Event Time !","slug":"event-time","link":"#event-time","children":[]},{"level":2,"title":"处理 Late Data","slug":"处理-late-data","link":"#处理-late-data","children":[]},{"level":2,"title":"OutputModes","slug":"outputmodes","link":"#outputmodes","children":[]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":2,"title":"扩展阅读","slug":"扩展阅读","link":"#扩展阅读","children":[]},{"level":2,"title":"参考资料","slug":"参考资料","link":"#参考资料","children":[]}],"git":{"updatedTime":1753237474000,"contributors":[{"name":"alice","username":"alice","email":"921757697@qq.com","commits":2,"url":"https://github.com/alice"}],"changelog":[{"hash":"245816fee7920b84913505a4353b6b4f934da7c0","time":1753237474000,"email":"921757697@qq.com","author":"alice","message":"uniapp 组件"},{"hash":"7706e85b299e47a4a064f79e4ce4f11f0e5f015c","time":1745114781000,"email":"921757697@qq.com","author":"alice","message":"doc 整理"}]},"filePathRelative":"guide/etl/spark/Structured-Streaming-之Event Time 解析.md"}');export{f as comp,E as data};
