


2016年毕业后，一直从事大数据平台开发相关工作，从0到1打造字节跳动数据集成产品，支持多种异构数据源间的海量数据同步，并提供离线、实时、全量、增量场景下全域数据集成解决方案，
目前支撑了数据集成需求。



技术要求：

1. 掌握Spark Core/SQL/Streaming，熟悉RDD/Dataset优化、Shuffle机制、内存管理；
2. 熟悉Flink DataStream/Table API、状态管理、Exactly-Once语义，有Flink SQL调优经验；
3. 