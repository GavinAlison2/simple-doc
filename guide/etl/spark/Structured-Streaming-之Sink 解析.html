<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <link rel="icon" href="/simple-doc/images/favicon.ico"><title>Structured Streaming 之 Sink 解析 | Blog</title><meta name="description" content="个人博客">
    <link rel="preload" href="/simple-doc/assets/style-B3-VMakp.css" as="style"><link rel="stylesheet" href="/simple-doc/assets/style-B3-VMakp.css">
    <link rel="modulepreload" href="/simple-doc/assets/app-DlGl6QFf.js"><link rel="modulepreload" href="/simple-doc/assets/Structured-Streaming-之Sink 解析.html-bXb36fKK.js"><link rel="modulepreload" href="/simple-doc/assets/20250420008-CWfxgdf_.js">
    <link rel="prefetch" href="/simple-doc/assets/index.html-DWJu9YS7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/bak-README.html-BXya8RJe.js" as="script"><link rel="prefetch" href="/simple-doc/assets/get-started.html-CGmKtWJK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/etl-resume.html-DNzhximg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/java-resume.html-PVR6NX1b.js" as="script"><link rel="prefetch" href="/simple-doc/assets/web3-resume.html-Ckr1S7aN.js" as="script"><link rel="prefetch" href="/simple-doc/assets/小程序.html-i7WEpKoA.js" as="script"><link rel="prefetch" href="/simple-doc/assets/时间规划.html-Bq-wS-_g.js" as="script"><link rel="prefetch" href="/simple-doc/assets/自媒体.html-BOYB_-7d.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-JVM什么样的对象直接进入老年代.html-C50hl18G.js" as="script"><link rel="prefetch" href="/simple-doc/assets/2-JVM双亲委派机制.html-Bl0guA83.js" as="script"><link rel="prefetch" href="/simple-doc/assets/3-JVM内存分布.html-lgrRlB1F.js" as="script"><link rel="prefetch" href="/simple-doc/assets/4-JVM内存分配.html-D3FSbnkF.js" as="script"><link rel="prefetch" href="/simple-doc/assets/5-gc.html-Dub9VLMs.js" as="script"><link rel="prefetch" href="/simple-doc/assets/6-解析Class文件.html-quU9C_3H.js" as="script"><link rel="prefetch" href="/simple-doc/assets/7-cmsGC的工作原理和致命缺陷.html-C54hIpYZ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/8-g1.html-Cp-SjnMo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CAEgBI8N.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-批量导入死锁问题.html-2exnukMW.js" as="script"><link rel="prefetch" href="/simple-doc/assets/如何排查问题cpu100_.html-CQFnCcR_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react-readme.html--D9s1AfG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react-simple.html-Bm27m1r6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react1-do.html-DEpfSYZP.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CXkgO3Q0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/min-project.html-8KxuCEWU.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BfDb8cms.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-decorator.html-B2YnVNBE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-quick-start.html-Z3Wb4sqo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-readme-viavideo.html-DDukKIKS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/typescript-readme.html-CxLvYmA5.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1.html-WpT4Yn3i.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-数据仓库工具箱-笔记.html-BUeRJBYv.js" as="script"><link rel="prefetch" href="/simple-doc/assets/2-数据产品经理的工作笔记.html-CICLWYgw.js" as="script"><link rel="prefetch" href="/simple-doc/assets/3-数据产品经理实战笔记.html-_1Of4QrQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CDJzSEoz.js" as="script"><link rel="prefetch" href="/simple-doc/assets/产品经理岗位分析.html-C-nCBbo4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/后端开发.html-CPsVFrxT.js" as="script"><link rel="prefetch" href="/simple-doc/assets/001-let-var-const.html-DcOADpNh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/002-let.html-C6vOWXGo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/003-constructor.html-BxdQOZ6k.js" as="script"><link rel="prefetch" href="/simple-doc/assets/004-rest-arg.html-B3p1JDHJ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/005-extend-expression.html-7u0otTzM.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-关键词.html-DDKTJwWE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/array.html-BmwT_Bvl.js" as="script"><link rel="prefetch" href="/simple-doc/assets/async-await.html-BpT6j9bL.js" as="script"><link rel="prefetch" href="/simple-doc/assets/closure.html-Cm2OMVrj.js" as="script"><link rel="prefetch" href="/simple-doc/assets/fun.html-BGixvPjQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/promise.html-Cy3A3IHi.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DAXROpJy.js" as="script"><link rel="prefetch" href="/simple-doc/assets/regex.html-DTcq0sv4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/string.html-D1gBrZQG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/高阶函数.html-CEltWSL0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/bigdata-readme.html-DV66h5rG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/dataworks.html-mvr2z-w5.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-start.html-Chh_uBSQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/notice.html-vBIc2b0a.js" as="script"><link rel="prefetch" href="/simple-doc/assets/resume.html-yk73x91o.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-BUNj_2l4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/元数据管理.html-DtUcQG2z.js" as="script"><link rel="prefetch" href="/simple-doc/assets/工作流集成方案.html-LbKGT7rb.js" as="script"><link rel="prefetch" href="/simple-doc/assets/数据开发.html-Dwd-5ti4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/数据计算方案.html-Dkda4HZ7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/数据集成方案.html-68K2v7yp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/调度方案.html-DZ7aFOF1.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-zEF0kXKs.js" as="script"><link rel="prefetch" href="/simple-doc/assets/BlockingQueue.html-DQxl7HL_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/DeplayQueue.html-DDeDQIMN.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-dCZbm5HU.js" as="script"><link rel="prefetch" href="/simple-doc/assets/手写线程池-思路.html-YIyq729u.js" as="script"><link rel="prefetch" href="/simple-doc/assets/手写线程池.html-CxYmfv2Q.js" as="script"><link rel="prefetch" href="/simple-doc/assets/线程池监控2.html-IXelJigS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/设计线程池监控.html-_YaDrASp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mmap.html-rq6xoaqs.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DyDmEHi9.js" as="script"><link rel="prefetch" href="/simple-doc/assets/same.html-DBmD_EoO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/innoDB.html-g_ZNQmLA.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mvcc.html-C50kXq6G.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-45讲.html-UhGO801t.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-Doublewrite.html-HNgM6nOK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-b_tree-插入与页分裂.html-aPWOxFg8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-basic.html-BVztYh2_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-binlog-redolog.html-DDH37Sfy.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-buffer-pool.html-CD55VP3e.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-bufferpool-freeflushlru.html-CO1AVsOD.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-changebuffer.html-DVenWQNg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-explained.html-B9nD2QfV.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-join.html-BcR7onkv.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-log.html-DJNI8d5y.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-log对应事务.html-Bm4DK9iE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-rbo-cbo.html-1MR-_tgp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-sql卡住.html-EGAlSwpA.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-内存自适应哈希索引.html-D8cIK4aZ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-思考整理.html-Ckx5gZ1G.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-执行逻辑.html-D5g-2zhF.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-索引.html-Dg4lW-0W.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-索引失效.html-CbNKQTZj.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-锁.html-DWB9-_f-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-面试题.html-9bYv4U1D.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-mV5l2WzS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-B9R6QS7A.js" as="script"><link rel="prefetch" href="/simple-doc/assets/手写MySQL.html-DBBplM1O.js" as="script"><link rel="prefetch" href="/simple-doc/assets/反欺诈系统.html-x8Eqm17m.js" as="script"><link rel="prefetch" href="/simple-doc/assets/urule.html-D3cWi4PB.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-iohNUYf8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-install.html-Bre0MbiN.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-official.html-BF-7d7F3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-readme.html-yeGPlB4o.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-todo.html-soVV3caj.js" as="script"><link rel="prefetch" href="/simple-doc/assets/uniapp-01.html-Duh8bJx6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/uniapp-02.html-D416uiW1.js" as="script"><link rel="prefetch" href="/simple-doc/assets/uniapp-basic-api.html-DsUOjoXm.js" as="script"><link rel="prefetch" href="/simple-doc/assets/uniapp-component.html-Bsp0drq4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/uniapp-deploy.html-DfZ2sEXg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DGAlgA4M.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test1.html-DzVC_F1b.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test2.html-Bo6ubhqY.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test3.html-8_VqgGNq.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-cli-command.html-DNAhVoMG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-cli.html-Bwm3c6xA.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-crud.html-BfVyCpCy.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-router.html-DGU35wKd.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-api.html-6vZnSbYS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-directive.html-K37QI_hQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-ops.html-zvfo9_eE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2.html-CIuuT2O8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue3-api.html-CaSpB1Dm.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue3-component.html-cb63dPFO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue3.html-nI4CZw2G.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vuex.html-CscbjwKX.js" as="script"><link rel="prefetch" href="/simple-doc/assets/resume.html-BzmYbUZp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/worker.html-eu1ruLdO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/some.html-BsE52z6f.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test1.html-BrV9y0Q3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test3.html-CtZvdfXY.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test4.html-DT42gQWR.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vuepress-install.html-CbdaXkhh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BVtPnWXn.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-kP445mr6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CaivQ4Sq.js" as="script"><link rel="prefetch" href="/simple-doc/assets/总结.html-DoIsOKw9.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CthQtrpi.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vote-do.html-B_RhlFrD.js" as="script"><link rel="prefetch" href="/simple-doc/assets/docker-compose搭建环境.html-DfGbRplr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/docker.html-Id8Q_er4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/docker01.html-BYS5BLrf.js" as="script"><link rel="prefetch" href="/simple-doc/assets/data-integration.html-hq1Q5NcT.js" as="script"><link rel="prefetch" href="/simple-doc/assets/case1-购房群体.html-C52IhNZ2.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter1-hadoop-hdfs.html-CeY7L8hh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter2-hadoop-yarn.html-gmylDHxx.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter3-hadoop-install-for-window.html-CC-VJpWr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter4-hadoop2.html-BEOqOWn3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BmXU9Ho0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.Hive-quickstart.html-D8B_p5_X.js" as="script"><link rel="prefetch" href="/simple-doc/assets/02.Hive-ddl.html-BXvwjJRh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/03.Hive-table.html-Bm1gDUdQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/04.Hive-index-view.html-B8khHcDk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/05.Hive-dml.html-B_BNJU4a.js" as="script"><link rel="prefetch" href="/simple-doc/assets/06.Hive-multi-partition.html-DMyol03L.js" as="script"><link rel="prefetch" href="/simple-doc/assets/07.Hive-query.html-Cp5RdcTb.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CIy112By.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter5-hive.html-D4k4ZCiU.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chaptere6-Hive简介及核心概念.html-DTgbtQOo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-数据倾斜.html-BLU9o6tn.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hadoop-install.html-DEmlA1J3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-install.html-CPCAb7uE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.rdd.html-Cg2PJnG_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.rdd2.html-DNaenhYs.js" as="script"><link rel="prefetch" href="/simple-doc/assets/02.dataframe.html-B109Ssnk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/03.dataset.html-DyYycDOs.js" as="script"><link rel="prefetch" href="/simple-doc/assets/06.graphx.html-B41qRCNS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/07.ml.html-DiWZaZr5.js" as="script"><link rel="prefetch" href="/simple-doc/assets/Structured-Streaming-之Event Time 解析.html-BwYFdFYP.js" as="script"><link rel="prefetch" href="/simple-doc/assets/Structured-Streaming-之Source 解析.html-NfVaquF1.js" as="script"><link rel="prefetch" href="/simple-doc/assets/Structured-Streaming-之Watermark 解析.html-C8DKIl4Z.js" as="script"><link rel="prefetch" href="/simple-doc/assets/Structured-Streaming-之状态存储解析.html-D9UbFCrv.js" as="script"><link rel="prefetch" href="/simple-doc/assets/Structured-Streaming-实现思路与实现概述 .html-DCbxV_xp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/broadcast.html-Px5HD3Wr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-PrNEVljI.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-code-quick-start.html-DxgSnXTk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-core.html-0J9oQz12.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-core2.html-BbY5T-Ih.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-executor.html-BO_tvXLh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-introduce.html-DiNeLZrM.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-kafka.html-cwc-kaYu.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-sql.html-Db22P5rr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-streaming.html-BUKe-e9O.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-数据倾斜.html-CtaoCi-F.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-DgwfK4Sc.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-kafka延迟队列.html-D1I0GhV7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01-02-sql执行.html-BXMMq-W6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/03-事务.html-5t4R2gtH.js" as="script"><link rel="prefetch" href="/simple-doc/assets/04-05-索引.html-DjH37cZY.js" as="script"><link rel="prefetch" href="/simple-doc/assets/06-07-锁.html-CBQff3Yk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/08-mvcc.html-CcwLSzNG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/09-普通索引和唯一索引.html-7KHxhCa_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/10-12-DirtyPag脏页.html-Bg3RmpUS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/13-17-临时表.html-Bp_VejYz.js" as="script"><link rel="prefetch" href="/simple-doc/assets/18-20-索引失效.html-C62nQAmz.js" as="script"><link rel="prefetch" href="/simple-doc/assets/21-25-mysql高可用.html-D8FdlDp7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/26-27-备库.html-CdmZXKe7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/28-读写分离有哪些坑.html-B3fHYbEY.js" as="script"><link rel="prefetch" href="/simple-doc/assets/29-33-数据库问题-查询多数内存不足.html-BCmSVSsN.js" as="script"><link rel="prefetch" href="/simple-doc/assets/34 -到底可不可以使用join.html-RK3c9JRV.js" as="script"><link rel="prefetch" href="/simple-doc/assets/35-Join语句优化.html-B0mFuvxa.js" as="script"><link rel="prefetch" href="/simple-doc/assets/36-39-临时表-自增主键.html-C6S1OqJa.js" as="script"><link rel="prefetch" href="/simple-doc/assets/40-insert语句的锁为什么这么多.html-DhgwtQpf.js" as="script"><link rel="prefetch" href="/simple-doc/assets/41-快速复制一张表.html-BIBUyLsr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/42-grant之后要flush.html-C0ccPdJJ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/43-分区表.html-D1ln2l2X.js" as="script"><link rel="prefetch" href="/simple-doc/assets/44-join问题.html-BKEnDTuW.js" as="script"><link rel="prefetch" href="/simple-doc/assets/45-id-over.html-LylCme0e.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-slow-log.html-_ePB3-7-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/mysql-删除大量数据.html-Db8R-crW.js" as="script"><link rel="prefetch" href="/simple-doc/assets/SQLAdvisor.html-ZryS15vZ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/soar.html-BQL8MuJq.js" as="script"><link rel="prefetch" href="/simple-doc/assets/env.html-De16g2Pp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/intro.html-BdeW72-3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BL5O97RK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DJ1CdehR.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-docker-install.html-B00bssCA.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-shell-install.html-LqJ6nuQz.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-standalone-install.html-CAD0otHT.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-D8LyNzNh.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BseqRgod.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-OiCxa3zd.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-Cf8zR0VE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-Bdvd4_NB.js" as="script"><link rel="prefetch" href="/simple-doc/assets/notice.html-CDVkEipC.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-BpoPA6YK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/404.html-BYebOV1D.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/simple-doc/"><img class="vp-site-logo" src="/simple-doc/images/logo.png" alt="Blog"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">Blog</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/simple-doc/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="前端"><span class="title">前端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="前端"><span class="title">前端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/vue/" aria-label="Vue"><!--[--><!--[--><!--]--><!--]-->Vue<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/Typescript/" aria-label="TypeScript"><!--[--><!--[--><!--]--><!--]-->TypeScript<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/React/" aria-label="React"><!--[--><!--[--><!--]--><!--]-->React<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Angular"><!--[--><!--[--><!--]--><!--]-->Angular<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="小程序"><!--[--><!--[--><!--]--><!--]-->小程序<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Flutter"><!--[--><!--[--><!--]--><!--]-->Flutter<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/datawarehouse/" aria-label="数据产品"><!--[--><!--[--><!--]--><!--]-->数据产品<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><!--[--><h4 class="vp-navbar-dropdown-subtitle"><a class="route-link auto-link" href="/simple-doc/guide/etl/bigdata-readme.html" aria-label="大数据"><!--[--><!--[--><!--]--><!--]-->大数据<!--[--><!--[--><!--]--><!--]--></a></h4><ul class="vp-navbar-dropdown-subitem-wrapper"><!--[--><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hadoop/" aria-label="Hadoop"><!--[--><!--[--><!--]--><!--]-->Hadoop<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hive/" aria-label="Hive"><!--[--><!--[--><!--]--><!--]-->Hive<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/simple-doc/guide/etl/spark/" aria-label="Spark"><!--[--><!--[--><!--]--><!--]-->Spark<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据库"><span class="title">数据库</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据库"><span class="title">数据库</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/mysql/" aria-label="MySQL"><!--[--><!--[--><!--]--><!--]-->MySQL<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Redis"><!--[--><!--[--><!--]--><!--]-->Redis<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="后端"><span class="title">后端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="后端"><span class="title">后端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Python"><!--[--><!--[--><!--]--><!--]-->Python<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Golang"><!--[--><!--[--><!--]--><!--]-->Golang<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/GavinAlison2" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->GitHub<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/simple-doc/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="前端"><span class="title">前端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="前端"><span class="title">前端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/vue/" aria-label="Vue"><!--[--><!--[--><!--]--><!--]-->Vue<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/Typescript/" aria-label="TypeScript"><!--[--><!--[--><!--]--><!--]-->TypeScript<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/React/" aria-label="React"><!--[--><!--[--><!--]--><!--]-->React<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Angular"><!--[--><!--[--><!--]--><!--]-->Angular<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="小程序"><!--[--><!--[--><!--]--><!--]-->小程序<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Flutter"><!--[--><!--[--><!--]--><!--]-->Flutter<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/datawarehouse/" aria-label="数据产品"><!--[--><!--[--><!--]--><!--]-->数据产品<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><!--[--><h4 class="vp-navbar-dropdown-subtitle"><a class="route-link auto-link" href="/simple-doc/guide/etl/bigdata-readme.html" aria-label="大数据"><!--[--><!--[--><!--]--><!--]-->大数据<!--[--><!--[--><!--]--><!--]--></a></h4><ul class="vp-navbar-dropdown-subitem-wrapper"><!--[--><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hadoop/" aria-label="Hadoop"><!--[--><!--[--><!--]--><!--]-->Hadoop<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hive/" aria-label="Hive"><!--[--><!--[--><!--]--><!--]-->Hive<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/simple-doc/guide/etl/spark/" aria-label="Spark"><!--[--><!--[--><!--]--><!--]-->Spark<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据库"><span class="title">数据库</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据库"><span class="title">数据库</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/mysql/" aria-label="MySQL"><!--[--><!--[--><!--]--><!--]-->MySQL<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Redis"><!--[--><!--[--><!--]--><!--]-->Redis<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="后端"><span class="title">后端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="后端"><span class="title">后端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Python"><!--[--><!--[--><!--]--><!--]-->Python<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Golang"><!--[--><!--[--><!--]--><!--]-->Golang<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/GavinAlison2" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->GitHub<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item vp-sidebar-heading" href="/simple-doc/guide/etl/spark/" aria-label="Spark 学习笔记"><!--[--><!--[--><!--]--><!--]-->Spark 学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="structured-streaming-之-sink-解析" tabindex="-1"><a class="header-anchor" href="#structured-streaming-之-sink-解析"><span>Structured Streaming 之 Sink 解析</span></a></h1><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">本文内容适用范围：</span>
<span class="line">* 2018.11.02 update, Spark 2.4 全系列 √ (已发布：2.4.0)</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>阅读本文前，请一定先阅读 <a class="route-link" href="/simple-doc/guide/etl/spark/Structured%20Streaming%20%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%E4%B8%8E%E5%AE%9E%E7%8E%B0%E6%A6%82%E8%BF%B0%20.html">Structured Streaming 实现思路与实现概述</a> 一文，其中概述了 Structured Streaming 的实现思路（包括 StreamExecution, Source, Sink 等在 Structured Streaming 里的作用），有了全局概念后再看本文的细节解释。</p><h2 id="引言" tabindex="-1"><a class="header-anchor" href="#引言"><span>引言</span></a></h2><p>Structured Streaming 非常显式地提出了输入(Source)、执行(StreamExecution)、输出(Sink)的 3 个组件，并且在每个组件显式地做到 fault-tolerant，由此得到整个 streaming 程序的 end-to-end exactly-once guarantees.</p><p>具体到源码上，Sink 是一个抽象的接口 <a href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/Sink.scala" target="_blank" rel="noopener noreferrer">trait Sink</a> [1]，只有一个方法：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">trait</span> Sink <span class="token punctuation">{</span></span>
<span class="line">  <span class="token keyword">def</span> addBatch<span class="token punctuation">(</span>batchId<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> data<span class="token operator">:</span> DataFrame<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个仅有的 <code>addBatch()</code> 方法支持了 Structured Streaming 实现 end-to-end exactly-once 处理所一定需要的功能。我们将马上解析这个 <code>addBatch()</code> 方法。</p><p>相比而言，前作 Spark Streaming 并没有对输出进行特别的抽象，而只是在 DStreamGraph [2] 里将一些 dstreams 标记为了 output。当需要 exactly-once 特性时，程序员可以根据当前批次的时间标识，来 <em><strong>自行维护和判断</strong></em> 一个批次是否已经执行过。</p><p>进化到 Structured Streaming 后，显式地抽象出了 Sink，并提供了一些原生幂等的 Sink 实现：</p><ul><li>已支持 <ul><li>HDFS-compatible file system，具体实现是 FileStreamSink extends Sink</li><li>Foreach sink，具体实现是 ForeachSink extends Sink</li><li>Kafka sink，具体实现是 KafkaSink extends Sink</li></ul></li><li>预计后续很快会支持 <ul><li>RDBMS</li></ul></li></ul><h2 id="sink-方法与功能" tabindex="-1"><a class="header-anchor" href="#sink-方法与功能"><span>Sink：方法与功能</span></a></h2><p>在 Structured Streaming 里，由 StreamExecution 作为持续查询的驱动器，分批次不断地：</p><p><img src="/simple-doc/assets/20250420008-Du7_w_xM.png" alt="Spark 1.0"></p><ol><li>在每个 StreamExecution 的批次最开始，StreamExecution 会向 Source 询问当前 Source 的最新进度，即最新的 offset</li><li>这个 Offset 给到 StreamExecution 后会被 StreamExecution 持久化到自己的 WAL 里</li><li>由 Source 根据 StreamExecution 所要求的 start offset、end offset，提供在 <code>(start, end]</code> 区间范围内的数据</li><li>StreamExecution 触发计算逻辑 logicalPlan 的优化与编译</li><li>把计算结果写出给 Sink <ul><li>具体是由 StreamExecution 调用 <code>Sink.addBatch(batchId: Long, data: DataFrame)</code></li><li>注意这时才会由 Sink 触发发生实际的取数据操作，以及计算过程</li><li>通常 Sink 直接可以直接把 <code>data: DataFrame</code> 的数据写出，并在完成后记录下 <code>batchId: Long</code></li><li>在故障恢复时，分两种情况讨论： <ul><li>(i) 如果上次执行在本步 <em><strong>结束前即失效</strong></em>，那么本次执行里 sink 应该完整写出计算结果</li><li>(ii) 如果上次执行在本步 <em><strong>结束后才失效</strong></em>，那么本次执行里 sink 可以重新写出计算结果（覆盖上次结果），也可以跳过写出计算结果（因为上次执行已经完整写出过计算结果了）</li></ul></li></ul></li><li>在数据完整写出到 Sink 后，StreamExecution 通知 Source 可以废弃数据；然后把成功的批次 id 写入到 batchCommitLog</li></ol><h2 id="sink-的具体实现-hdfs-api-compatible-fs-foreach" tabindex="-1"><a class="header-anchor" href="#sink-的具体实现-hdfs-api-compatible-fs-foreach"><span>Sink 的具体实现：HDFS-API compatible FS, Foreach</span></a></h2><h3 id="a-具体实现-hdfs-api-compatible-fs" tabindex="-1"><a class="header-anchor" href="#a-具体实现-hdfs-api-compatible-fs"><span>(a) 具体实现: HDFS-API compatible FS</span></a></h3><p>通常我们使用如下方法方法写出到 HDFS-API compatible FS:</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">writeStream</span>
<span class="line">  <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;parquet&quot;</span><span class="token punctuation">)</span>      <span class="token comment">// parquet, csv, json, text, orc ...</span></span>
<span class="line">  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;checkpointLocation&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;path/to/checkpoint/dir&quot;</span><span class="token punctuation">)</span></span>
<span class="line">  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;path&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;path/to/destination/dir&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么我们看这里 <code>FileStreamSink</code> 具体的 <code>addBatch()</code> 实现是：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">  <span class="token comment">// 来自：class FileStreamSink extends Sink</span></span>
<span class="line">  <span class="token comment">// 版本：Spark 2.1.0</span></span>
<span class="line">  <span class="token keyword">override</span> <span class="token keyword">def</span> addBatch<span class="token punctuation">(</span>batchId<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> data<span class="token operator">:</span> DataFrame<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">/* 首先根据持久化的 fileLog 来判断这个 batchId 是否已经写出过 */</span></span>
<span class="line">    <span class="token keyword">if</span> <span class="token punctuation">(</span>batchId <span class="token operator">&lt;=</span> fileLog<span class="token punctuation">.</span>getLatest<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">/* 如果 batchId 已经完整写出过，则本次跳过 addBatch */</span></span>
<span class="line">      logInfo<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;Skipping already committed batch </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">batchId</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">/* 本次需要具体执行写出 data */</span></span>
<span class="line">      <span class="token comment">/* 初始化 FileCommitter -- FileCommitter 能正确处理 task 推测执行、task 失败重做等情况 */</span></span>
<span class="line">      <span class="token keyword">val</span> committer <span class="token operator">=</span> FileCommitProtocol<span class="token punctuation">.</span>instantiate<span class="token punctuation">(</span></span>
<span class="line">        className <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sessionState<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>streamingFileCommitProtocolClass<span class="token punctuation">,</span></span>
<span class="line">        jobId <span class="token operator">=</span> batchId<span class="token punctuation">.</span>toString<span class="token punctuation">,</span></span>
<span class="line">        outputPath <span class="token operator">=</span> path<span class="token punctuation">,</span></span>
<span class="line">        isAppend <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">      committer <span class="token keyword">match</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">case</span> manifestCommitter<span class="token operator">:</span> ManifestFileCommitProtocol <span class="token keyword">=&gt;</span></span>
<span class="line">          manifestCommitter<span class="token punctuation">.</span>setupManifestOptions<span class="token punctuation">(</span>fileLog<span class="token punctuation">,</span> batchId<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">case</span> _ <span class="token keyword">=&gt;</span>  <span class="token comment">// Do nothing</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">      <span class="token comment">/* 获取需要做 partition 的 columns */</span></span>
<span class="line">      <span class="token keyword">val</span> partitionColumns<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Attribute<span class="token punctuation">]</span> <span class="token operator">=</span> partitionColumnNames<span class="token punctuation">.</span>map <span class="token punctuation">{</span> col <span class="token keyword">=&gt;</span></span>
<span class="line">        <span class="token keyword">val</span> nameEquality <span class="token operator">=</span> data<span class="token punctuation">.</span>sparkSession<span class="token punctuation">.</span>sessionState<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>resolver</span>
<span class="line">        data<span class="token punctuation">.</span>logicalPlan<span class="token punctuation">.</span>output<span class="token punctuation">.</span>find<span class="token punctuation">(</span>f <span class="token keyword">=&gt;</span> nameEquality<span class="token punctuation">(</span>f<span class="token punctuation">.</span>name<span class="token punctuation">,</span> col<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse <span class="token punctuation">{</span></span>
<span class="line">          <span class="token keyword">throw</span> <span class="token keyword">new</span> RuntimeException<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;Partition column </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">col</span></span><span class="token string"> not found in schema </span><span class="token interpolation"><span class="token punctuation">${</span><span class="token expression">data<span class="token punctuation">.</span>schema</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">      <span class="token comment">/* 真正写出数据 */</span></span>
<span class="line">      FileFormatWriter<span class="token punctuation">.</span>write<span class="token punctuation">(</span></span>
<span class="line">        sparkSession <span class="token operator">=</span> sparkSession<span class="token punctuation">,</span></span>
<span class="line">        queryExecution <span class="token operator">=</span> data<span class="token punctuation">.</span>queryExecution<span class="token punctuation">,</span></span>
<span class="line">        fileFormat <span class="token operator">=</span> fileFormat<span class="token punctuation">,</span></span>
<span class="line">        committer <span class="token operator">=</span> committer<span class="token punctuation">,</span></span>
<span class="line">        outputSpec <span class="token operator">=</span> FileFormatWriter<span class="token punctuation">.</span>OutputSpec<span class="token punctuation">(</span>path<span class="token punctuation">,</span> Map<span class="token punctuation">.</span>empty<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">        hadoopConf <span class="token operator">=</span> hadoopConf<span class="token punctuation">,</span></span>
<span class="line">        partitionColumns <span class="token operator">=</span> partitionColumns<span class="token punctuation">,</span></span>
<span class="line">        bucketSpec <span class="token operator">=</span> None<span class="token punctuation">,</span></span>
<span class="line">        refreshFunction <span class="token operator">=</span> _ <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">        options <span class="token operator">=</span> options<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="b-具体实现-foreach" tabindex="-1"><a class="header-anchor" href="#b-具体实现-foreach"><span>(b) 具体实现: Foreach</span></a></h3><p>通常我们使用如下方法写出到 foreach sink:</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">writeStream</span>
<span class="line">  <span class="token comment">/* 假设进来的每条数据是 String 类型的 */</span></span>
<span class="line">  <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token keyword">new</span> ForeachWriter<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">/* 每个 partition 即每个 task 会在开始时调用此 open() 方法 */</span></span>
<span class="line">    <span class="token comment">/* 注意对于同一个 partitionId/version，此方法可能被先后调用多次，如 task 失效重做时 */</span></span>
<span class="line">    <span class="token comment">/* 注意对于同一个 partitionId/version，此方法也可能被同时调用，如推测执行时 */</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>partitionId<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> version<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">      println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;open(</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">partitionId</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">version</span></span><span class="token string">)&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token boolean">true</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">/* 此 partition 内即每个 task 内的每条数据，此方法都被调用 */</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> process<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;process </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">value</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token comment">/* 正常结束或异常结束时，此方法被调用。但一些异常情况时，此方法不一定被调用。 */</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> close<span class="token punctuation">(</span>errorOrNull<span class="token operator">:</span> Throwable<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;close(</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">errorOrNull</span></span><span class="token string">)&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">  <span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么我们看这里 <code>ForeachSink</code> 具体的 <code>addBatch()</code> 实现是：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">  <span class="token comment">// 来自：class ForeachSink extends Sink with Serializable</span></span>
<span class="line">  <span class="token comment">// 版本：Spark 2.1.0</span></span>
<span class="line">  <span class="token keyword">override</span> <span class="token keyword">def</span> addBatch<span class="token punctuation">(</span>batchId<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> data<span class="token operator">:</span> DataFrame<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">val</span> encoder <span class="token operator">=</span> encoderFor<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">.</span>resolveAndBind<span class="token punctuation">(</span></span>
<span class="line">      data<span class="token punctuation">.</span>logicalPlan<span class="token punctuation">.</span>output<span class="token punctuation">,</span></span>
<span class="line">      data<span class="token punctuation">.</span>sparkSession<span class="token punctuation">.</span>sessionState<span class="token punctuation">.</span>analyzer<span class="token punctuation">)</span></span>
<span class="line">    <span class="token comment">/* 是 rdd 的 foreachPartition，即是 task 级别 */</span></span>
<span class="line">    data<span class="token punctuation">.</span>queryExecution<span class="token punctuation">.</span>toRdd<span class="token punctuation">.</span>foreachPartition <span class="token punctuation">{</span> iter <span class="token keyword">=&gt;</span></span>
<span class="line">      <span class="token comment">/* partition/task 级别的 open */</span></span>
<span class="line">      <span class="token keyword">if</span> <span class="token punctuation">(</span>writer<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span>TaskContext<span class="token punctuation">.</span>getPartitionId<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batchId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">try</span> <span class="token punctuation">{</span></span>
<span class="line">          <span class="token keyword">while</span> <span class="token punctuation">(</span>iter<span class="token punctuation">.</span>hasNext<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token comment">/* 对每条数据调用 process() 方法 */</span></span>
<span class="line">            writer<span class="token punctuation">.</span>process<span class="token punctuation">(</span>encoder<span class="token punctuation">.</span>fromRow<span class="token punctuation">(</span>iter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">          <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span></span>
<span class="line">          <span class="token keyword">case</span> e<span class="token operator">:</span> Throwable <span class="token keyword">=&gt;</span></span>
<span class="line">            <span class="token comment">/* 异常时调用 close() 方法 */</span></span>
<span class="line">            writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span>e<span class="token punctuation">)</span></span>
<span class="line">            <span class="token keyword">throw</span> e</span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">        <span class="token comment">/* 正常写完调用 close() 方法 */</span></span>
<span class="line">        writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token keyword">null</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token comment">/* 不写数据、直接调用 close() 方法 */</span></span>
<span class="line">        writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token keyword">null</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>所以我们看到，foreach sink 需要使用者提供 writer，所以这里的可定制度就非常高。</p><p>但是仍然需要注意，由于 foreach 的 writer 可能被 open() 多次，可能有多个 task 同时调用一个 writer。所以推荐 writer 一定要写成幂等的，如果 writer 不幂等、那么 Structured Streaming 框架本身也没有更多的办法能够保证 end-to-end exactly-once guarantees 了。</p><h3 id="c-具体实现-kafka" tabindex="-1"><a class="header-anchor" href="#c-具体实现-kafka"><span>(c) 具体实现: Kafka</span></a></h3><p>Spark 2.1.1 版本开始加入了 KafkaSink，使得 Spark 也能够将数据写入到 kafka 中。</p><p>通常我们使用如下方法写出到 kafka sink:</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">writeStream</span>
<span class="line">  <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;kafka&quot;</span><span class="token punctuation">)</span></span>
<span class="line">  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;checkpointLocation&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span></span>
<span class="line">  <span class="token punctuation">.</span>outputMode<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span></span>
<span class="line">  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;kafka.bootstrap.servers&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment">// 写出到哪个集群</span></span>
<span class="line">  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;topic&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment">// 写出到哪个 topic</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么我们看这里 <code>KafkaSink</code> 具体的 <code>addBatch()</code> 实现是：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">  <span class="token comment">// 来自：class KafkaSink extends Sink</span></span>
<span class="line">  <span class="token comment">// 版本：Spark 2.1.1, 2.2.0</span></span>
<span class="line">  <span class="token keyword">override</span> <span class="token keyword">def</span> addBatch<span class="token punctuation">(</span>batchId<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> data<span class="token operator">:</span> DataFrame<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">if</span> <span class="token punctuation">(</span>batchId <span class="token operator">&lt;=</span> latestBatchId<span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">      logInfo<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;Skipping already committed batch </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">batchId</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token comment">// 主要是通过 KafkaWriter.write() 来做写出；</span></span>
<span class="line">      <span class="token comment">// 在 KafkaWriter.write() 里，主要是继续通过 KafkaWriteTask.execute() 来做写出</span></span>
<span class="line">      KafkaWriter<span class="token punctuation">.</span>write<span class="token punctuation">(</span>sqlContext<span class="token punctuation">.</span>sparkSession<span class="token punctuation">,</span></span>
<span class="line">        data<span class="token punctuation">.</span>queryExecution<span class="token punctuation">,</span> executorKafkaParams<span class="token punctuation">,</span> topic<span class="token punctuation">)</span></span>
<span class="line">      latestBatchId <span class="token operator">=</span> batchId</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么我们继续看这里 <code>KafkaWriteTask</code> 具体的 <code>execute()</code> 实现是：</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">  <span class="token comment">// 来自：class KafkaWriteTask</span></span>
<span class="line">  <span class="token comment">// 版本：Spark 2.1.1, 2.2.0</span></span>
<span class="line">  <span class="token keyword">def</span> execute<span class="token punctuation">(</span>iterator<span class="token operator">:</span> Iterator<span class="token punctuation">[</span>InternalRow<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    producer <span class="token operator">=</span> <span class="token keyword">new</span> KafkaProducer<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Byte</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Array<span class="token punctuation">[</span><span class="token builtin">Byte</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span>producerConfiguration<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">while</span> <span class="token punctuation">(</span>iterator<span class="token punctuation">.</span>hasNext <span class="token operator">&amp;&amp;</span> failedWrite <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token keyword">val</span> currentRow <span class="token operator">=</span> iterator<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token comment">// 这里的 projection 主要是构建 projectedRow，使得：</span></span>
<span class="line">      <span class="token comment">// 其第 0 号元素是 topic</span></span>
<span class="line">      <span class="token comment">// 其第 1 号元素是 key 的 binary 表示</span></span>
<span class="line">      <span class="token comment">// 其第 2 号元素是 value 的 binary 表示</span></span>
<span class="line">      <span class="token keyword">val</span> projectedRow <span class="token operator">=</span> projection<span class="token punctuation">(</span>currentRow<span class="token punctuation">)</span></span>
<span class="line">      <span class="token keyword">val</span> topic <span class="token operator">=</span> projectedRow<span class="token punctuation">.</span>getUTF8String<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token keyword">val</span> key <span class="token operator">=</span> projectedRow<span class="token punctuation">.</span>getBinary<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token keyword">val</span> value <span class="token operator">=</span> projectedRow<span class="token punctuation">.</span>getBinary<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token keyword">if</span> <span class="token punctuation">(</span>topic <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">throw</span> <span class="token keyword">new</span> NullPointerException<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;null topic present in the data. Use the &quot;</span></span> <span class="token operator">+</span></span>
<span class="line">        <span class="token string-interpolation"><span class="token id function">s</span><span class="token string">&quot;</span><span class="token interpolation"><span class="token punctuation">${</span><span class="token expression">KafkaSourceProvider<span class="token punctuation">.</span>TOPIC_OPTION_KEY</span><span class="token punctuation">}</span></span><span class="token string"> option for setting a default topic.&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">      <span class="token keyword">val</span> record <span class="token operator">=</span> <span class="token keyword">new</span> ProducerRecord<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Byte</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Array<span class="token punctuation">[</span><span class="token builtin">Byte</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span>topic<span class="token punctuation">.</span>toString<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">)</span></span>
<span class="line">      <span class="token keyword">val</span> callback <span class="token operator">=</span> <span class="token keyword">new</span> Callback<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">override</span> <span class="token keyword">def</span> onCompletion<span class="token punctuation">(</span>recordMetadata<span class="token operator">:</span> RecordMetadata<span class="token punctuation">,</span> e<span class="token operator">:</span> Exception<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">          <span class="token keyword">if</span> <span class="token punctuation">(</span>failedWrite <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> e <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            failedWrite <span class="token operator">=</span> e</span>
<span class="line">          <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">      producer<span class="token punctuation">.</span>send<span class="token punctuation">(</span>record<span class="token punctuation">,</span> callback<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里我们需要说明的是，由于 Spark 本身会失败重做 —— 包括单个 task 的失败重做、stage 的失败重做、整个拓扑的失败重做等 —— 那么同一条数据可能被写入到 kafka 一次以上。由于 kafka 目前还不支持 transactional write，所以多写入的数据不能被撤销，会造成一些重复。当然 kafka 自身的高可用写入（比如写入 broker 了的数据的 ack 消息没有成功送达 producer，导致 producer 重新发送数据时），也有可能造成重复。</p><p>在 kafka 支持 transactional write 之前，可能需要下游实现下去重机制。比如如果下游仍然是 Structured Streaming，那么可以使用 streaming deduplication 来获得去重后的结果。</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>我们总结一下截至目前，Sink 已有的具体实现：</p><table><thead><tr><th style="text-align:center;">Sinks</th><th style="text-align:center;">是否幂等写入</th><th style="text-align:center;">原生内置支持</th><th style="text-align:center;">注解</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>HDFS-compatible file system</strong></td><td style="text-align:center;">√</td><td style="text-align:center;">已支持</td><td style="text-align:center;">包括但不限于 text, json, csv, parquet, orc, ...</td></tr><tr><td style="text-align:center;"><strong>ForeachSink</strong> (自定操作幂等)</td><td style="text-align:center;">√</td><td style="text-align:center;">已支持</td><td style="text-align:center;">可定制度非常高的 sink</td></tr><tr><td style="text-align:center;"><strong>Kafka</strong></td><td style="text-align:center;">×</td><td style="text-align:center;">已支持</td><td style="text-align:center;">Kafka 目前不支持幂等写入，所以可能会有重复写入<br>（但推荐接着 Kafka 使用 streaming de-duplication 来去重）</td></tr><tr><td style="text-align:center;"><strong>ForeachSink</strong> (自定操作不幂等)</td><td style="text-align:center;">×</td><td style="text-align:center;">已支持</td><td style="text-align:center;">不推荐使用不幂等的自定操作</td></tr></tbody></table><p>这里我们特别强调一下，虽然 Structured Streaming 也内置了 <code>console</code> 这个 Source，但其实它的主要用途只是在技术会议/讲座上做 demo，不应用于线上生产系统。</p><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ol><li><a href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/Sink.scala" target="_blank" rel="noopener noreferrer">Github: org/apache/spark/sql/execution/streaming/Sink.scala</a></li><li><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/DStreamGraph.scala" target="_blank" rel="noopener noreferrer">Github: org/apache/spark/streaming/DStreamGraph.scala</a></li></ol><br><br></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">最近更新：: </span><time class="meta-item-info" datetime="2025-07-23T02:24:34.000Z" data-allow-mismatch>2025/7/23 02:24</time></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 921757697@qq.com">alice</span><!----><!--]--><!--]--></span></div></div></footer><!----><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/simple-doc/assets/app-DlGl6QFf.js" defer></script>
  </body>
</html>
