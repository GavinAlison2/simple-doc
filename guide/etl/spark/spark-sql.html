<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <link rel="icon" href="/simple-doc/images/favicon.ico"><title>SparkSQL | Blog</title><meta name="description" content="个人博客">
    <link rel="preload" href="/simple-doc/assets/style-B3-VMakp.css" as="style"><link rel="stylesheet" href="/simple-doc/assets/style-B3-VMakp.css">
    <link rel="modulepreload" href="/simple-doc/assets/app-CNZ6fT6P.js"><link rel="modulepreload" href="/simple-doc/assets/spark-sql.html-D44dNCiO.js">
    <link rel="prefetch" href="/simple-doc/assets/index.html-BQqcdGSn.js" as="script"><link rel="prefetch" href="/simple-doc/assets/bak-README.html-7l_WO_xe.js" as="script"><link rel="prefetch" href="/simple-doc/assets/get-started.html-BRmxrPlo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/自媒体.html-DU3L_ag8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react-readme.html-JW3FkfKP.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react-simple.html-CcbjVPq0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/react1-do.html-C0ka4JPw.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-D8qWKWq0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/min-project.html-BoDoux84.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-UT2FXh1E.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-decorator.html-CG6W6TTV.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-quick-start.html-CcgMXkAk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/ts-readme-viavideo.html-CIgj6MnE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/typescript-readme.html-BmBNgbP9.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1.html-eV1Bfw2v.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-数据仓库工具箱-笔记.html-CXYYycgT.js" as="script"><link rel="prefetch" href="/simple-doc/assets/2-数据产品经理的工作笔记.html-CkTB0mTo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/3-数据产品经理实战笔记.html-CPWL5hYJ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DzLvFakR.js" as="script"><link rel="prefetch" href="/simple-doc/assets/产品经理岗位分析.html-1UJKMCYe.js" as="script"><link rel="prefetch" href="/simple-doc/assets/后端开发.html-Cx_oyNDa.js" as="script"><link rel="prefetch" href="/simple-doc/assets/001-let-var-const.html-Da8vRz7d.js" as="script"><link rel="prefetch" href="/simple-doc/assets/002-let.html-BrdfwWFk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/003-constructor.html-BfcqA_m0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/004-rest-arg.html-DuI5VOXk.js" as="script"><link rel="prefetch" href="/simple-doc/assets/005-extend-expression.html-K_f-qqY3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/1-关键词.html-DYGSqdFO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/array.html-BKngykLQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/async-await.html-CHWuKYUK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/closure.html-t4Fd_OTq.js" as="script"><link rel="prefetch" href="/simple-doc/assets/fun.html-GadsrwUp.js" as="script"><link rel="prefetch" href="/simple-doc/assets/promise.html-DURjaC5P.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BqCWW66d.js" as="script"><link rel="prefetch" href="/simple-doc/assets/regex.html-ebR3w3bt.js" as="script"><link rel="prefetch" href="/simple-doc/assets/string.html-t6ZZViI4.js" as="script"><link rel="prefetch" href="/simple-doc/assets/高阶函数.html-BXVNKiIx.js" as="script"><link rel="prefetch" href="/simple-doc/assets/bigdata-readme.html-CSjY7Hyt.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-start.html-DoCrapjg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/notice.html-BtGIy6kt.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-CfARG53H.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-CGODjbwi.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BN_CqhIj.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BNWsGlzX.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-Cdsc2Lxi.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-install.html-DtV94y75.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-official.html-Cns2cwSC.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-readme.html-DsjS_rQo.js" as="script"><link rel="prefetch" href="/simple-doc/assets/tailwind-todo.html-lfu8GKpO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BGa9JsqP.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test1.html-0BOqRFjR.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test2.html-I2XzZ9pD.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test3.html-BN0eVx5b.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-cli-command.html-CowLE6IM.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-cli.html-DxRLuUnC.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-crud.html-CpVZikcS.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue-router.html-CbTbXr0R.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-api.html-Dc_y1KPG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-directive.html-Cb_yil_h.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2-ops.html-BtpHbaks.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue2.html-DHOKGah5.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue3-component.html-Chf4FajO.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vue3.html-1v5c5Rhq.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vuex.html-BHBHvquZ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/worker.html-DP18Fq3T.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test1.html-BM898n9D.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test3.html-D1XSAxIK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/test4.html-D4pX2Xx0.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vuepress-install.html-Cy4aI-_l.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-R8f7Ipgu.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-qyOWAQ-S.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BxaZIx_S.js" as="script"><link rel="prefetch" href="/simple-doc/assets/总结.html-CthVO2Yr.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-missJnKm.js" as="script"><link rel="prefetch" href="/simple-doc/assets/vote-do.html-B3ten7OJ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter1-hadoop-hdfs.html-B1JTKK2Z.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter2-hadoop-yarn.html-BMx0ZxG-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter3-hadoop-install-for-window.html-DXoVk3B2.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter4-hadoop2.html-Cf14FanJ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-B0Q7olxU.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.Hive-quickstart.html-Dd0W7zri.js" as="script"><link rel="prefetch" href="/simple-doc/assets/02.Hive-ddl.html-Baeuc0o5.js" as="script"><link rel="prefetch" href="/simple-doc/assets/03.Hive-table.html-C6X32VKc.js" as="script"><link rel="prefetch" href="/simple-doc/assets/04.Hive-index-view.html-BuYlqAWc.js" as="script"><link rel="prefetch" href="/simple-doc/assets/05.Hive-dml.html-CmEkpoe8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/06.Hive-multi-partition.html-E_wVMP-A.js" as="script"><link rel="prefetch" href="/simple-doc/assets/07.Hive-query.html-DqeXBbhT.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BHx8dvBK.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chapter5-hive.html-yFxxnDto.js" as="script"><link rel="prefetch" href="/simple-doc/assets/chaptere6-Hive简介及核心概念.html-GPD0i_S2.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-数据倾斜.html-C2E-fr7F.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hadoop-install.html-BxeF1Chb.js" as="script"><link rel="prefetch" href="/simple-doc/assets/hive-install.html-DYsaNfKD.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.rdd.html-dw9Ks02U.js" as="script"><link rel="prefetch" href="/simple-doc/assets/01.rdd2.html-fI7fpWXg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/02.dataframe.html-BbsuokMQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/03.dataset.html-8cwx2irg.js" as="script"><link rel="prefetch" href="/simple-doc/assets/06.graphx.html-Dw5S45H7.js" as="script"><link rel="prefetch" href="/simple-doc/assets/07.ml.html-CEYPcbk1.js" as="script"><link rel="prefetch" href="/simple-doc/assets/broadcast.html-BDxxwtN8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-C6AV69M2.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-code-quick-start.html-8NYAJOx8.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-core.html-C4KC_nR3.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-core2.html-CwfUXHe1.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-executor.html-CsbJE8NH.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-introduce.html-CgcIKoZa.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-kafka.html-BZrmzLAQ.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-streaming.html-Cb74j1E6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-数据倾斜.html-CcHygChw.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-BusRL2Ft.js" as="script"><link rel="prefetch" href="/simple-doc/assets/env.html-BuzziF6-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/intro.html-BDW_5O85.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-BzYfftUE.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-JEL0ukf-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-docker-install.html-BXaGuZ_-.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-shell-install.html-BM3HLuQD.js" as="script"><link rel="prefetch" href="/simple-doc/assets/spark-standalone-install.html-djDufSae.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-Q0FmHSl_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-HBlgMq6_.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-D9x9mOFl.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-B4KghjfF.js" as="script"><link rel="prefetch" href="/simple-doc/assets/index.html-DNhPyigw.js" as="script"><link rel="prefetch" href="/simple-doc/assets/notice.html-CYzYFddG.js" as="script"><link rel="prefetch" href="/simple-doc/assets/todo.html-DZuctH_6.js" as="script"><link rel="prefetch" href="/simple-doc/assets/404.html-DLhbf6_M.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/simple-doc/"><img class="vp-site-logo" src="/simple-doc/images/logo.png" alt="Blog"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">Blog</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/simple-doc/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="前端"><span class="title">前端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="前端"><span class="title">前端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/vue/" aria-label="Vue"><!--[--><!--[--><!--]--><!--]-->Vue<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/Typescript/" aria-label="TypeScript"><!--[--><!--[--><!--]--><!--]-->TypeScript<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/React/" aria-label="React"><!--[--><!--[--><!--]--><!--]-->React<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Angular"><!--[--><!--[--><!--]--><!--]-->Angular<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="小程序"><!--[--><!--[--><!--]--><!--]-->小程序<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Flutter"><!--[--><!--[--><!--]--><!--]-->Flutter<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/datawarehouse/" aria-label="数据产品"><!--[--><!--[--><!--]--><!--]-->数据产品<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><!--[--><h4 class="vp-navbar-dropdown-subtitle"><a class="route-link auto-link" href="/simple-doc/guide/etl/bigdata-readme.html" aria-label="大数据"><!--[--><!--[--><!--]--><!--]-->大数据<!--[--><!--[--><!--]--><!--]--></a></h4><ul class="vp-navbar-dropdown-subitem-wrapper"><!--[--><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hadoop/" aria-label="Hadoop"><!--[--><!--[--><!--]--><!--]-->Hadoop<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hive/" aria-label="Hive"><!--[--><!--[--><!--]--><!--]-->Hive<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/simple-doc/guide/etl/spark/" aria-label="Spark"><!--[--><!--[--><!--]--><!--]-->Spark<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据库"><span class="title">数据库</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据库"><span class="title">数据库</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/mysql/" aria-label="MySQL"><!--[--><!--[--><!--]--><!--]-->MySQL<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Redis"><!--[--><!--[--><!--]--><!--]-->Redis<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="后端"><span class="title">后端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="后端"><span class="title">后端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Python"><!--[--><!--[--><!--]--><!--]-->Python<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Golang"><!--[--><!--[--><!--]--><!--]-->Golang<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/GavinAlison2" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->GitHub<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/simple-doc/" aria-label="首页"><!--[--><!--[--><!--]--><!--]-->首页<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="前端"><span class="title">前端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="前端"><span class="title">前端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/vue/" aria-label="Vue"><!--[--><!--[--><!--]--><!--]-->Vue<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/Typescript/" aria-label="TypeScript"><!--[--><!--[--><!--]--><!--]-->TypeScript<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/React/" aria-label="React"><!--[--><!--[--><!--]--><!--]-->React<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Angular"><!--[--><!--[--><!--]--><!--]-->Angular<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Node.js"><!--[--><!--[--><!--]--><!--]-->Node.js<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="小程序"><!--[--><!--[--><!--]--><!--]-->小程序<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Flutter"><!--[--><!--[--><!--]--><!--]-->Flutter<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据开发"><span class="title">数据开发</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/datawarehouse/" aria-label="数据产品"><!--[--><!--[--><!--]--><!--]-->数据产品<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><!--[--><h4 class="vp-navbar-dropdown-subtitle"><a class="route-link auto-link" href="/simple-doc/guide/etl/bigdata-readme.html" aria-label="大数据"><!--[--><!--[--><!--]--><!--]-->大数据<!--[--><!--[--><!--]--><!--]--></a></h4><ul class="vp-navbar-dropdown-subitem-wrapper"><!--[--><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hadoop/" aria-label="Hadoop"><!--[--><!--[--><!--]--><!--]-->Hadoop<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link auto-link" href="/simple-doc/guide/etl/hive/" aria-label="Hive"><!--[--><!--[--><!--]--><!--]-->Hive<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/simple-doc/guide/etl/spark/" aria-label="Spark"><!--[--><!--[--><!--]--><!--]-->Spark<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="数据库"><span class="title">数据库</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="数据库"><span class="title">数据库</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/guide/mysql/" aria-label="MySQL"><!--[--><!--[--><!--]--><!--]-->MySQL<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Redis"><!--[--><!--[--><!--]--><!--]-->Redis<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><div class="vp-navbar-dropdown-wrapper"><button class="vp-navbar-dropdown-title" type="button" aria-label="后端"><span class="title">后端</span><span class="arrow down"></span></button><button class="vp-navbar-dropdown-title-mobile" type="button" aria-label="后端"><span class="title">后端</span><span class="right arrow"></span></button><ul style="display:none;" class="vp-navbar-dropdown"><!--[--><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Java"><!--[--><!--[--><!--]--><!--]-->Java<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Python"><!--[--><!--[--><!--]--><!--]-->Python<!--[--><!--[--><!--]--><!--]--></a></li><li class="vp-navbar-dropdown-item"><a class="route-link auto-link" href="/simple-doc/pages/folder1/test1.html" aria-label="Golang"><!--[--><!--[--><!--]--><!--]-->Golang<!--[--><!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/GavinAlison2" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->GitHub<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><a class="route-link route-link-active auto-link vp-sidebar-item vp-sidebar-heading" href="/simple-doc/guide/etl/spark/" aria-label="Spark 学习笔记"><!--[--><!--[--><!--]--><!--]-->Spark 学习笔记<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h1 id="sparksql" tabindex="-1"><a class="header-anchor" href="#sparksql"><span>SparkSQL</span></a></h1><h2 id="_1-1-sparksql-是什么" tabindex="-1"><a class="header-anchor" href="#_1-1-sparksql-是什么"><span>1.1 SparkSQL 是什么</span></a></h2><p>Spark SQL 是 Spark 用于结构化数据(structured data)处理的 Spark 模块。</p><h2 id="_1-2-hive-and-sparksql" tabindex="-1"><a class="header-anchor" href="#_1-2-hive-and-sparksql"><span>1.2 Hive and SparkSQL</span></a></h2><p>SparkSQL 的前身是 Shark，给熟悉 RDBMS 但又不理解 MapReduce 的技术人员提供快速上手的工具。Hive 是早期唯一运行在 Hadoop 上的 SQL-on-Hadoop 工具。但是 MapReduce 计算过程中大量的中间磁盘落地过程消耗了大量的 I/O，降低的运行效率，为了提高 SQL-on-Hadoop的效率，大量的 SQL-on-Hadoop 工具开始产生，其中表现较为突出的是：</p><ul><li>Drill</li><li>Impala</li><li>Shark</li></ul><p>其中 Shark 是伯克利实验室 Spark 生态环境的组件之一，是基于 Hive 所开发的工具，它修改了下图所示的右下角的内存管理、物理计划、执行三个模块，并使之能运行在 Spark 引擎上。</p><p><img src="/simple-doc/assets/image-20250418006-BvuLrHr6.png" alt="06"></p><ul><li><p>Shark 的出现，使得 SQL-on-Hadoop 的性能比 Hive 有了 10-100 倍的提高。但是，随着 Spark 的发展，对于野心勃勃的Spark 团队来说，Shark 对于 Hive 的太多依赖（如采用 Hive 的语法解析器、查询优化器等等），制约了 Spark 的 One Stack Rule Them All的既定方针，制约了 Spark 各个组件的相互集成，所以提出了 SparkSQL 项目。SparkSQL抛弃原有 Shark 的代码，汲取了 Shark 的一些优点，如内存列存储（In-Memory Columnar Storage）、Hive兼容性等，重新开发了SparkSQL代码；由于摆脱了对Hive的依赖性，SparkSQL无论在<code>数据兼容</code>、<code>性能优化</code>、<code>组件扩展</code>方面都得到了极大的方便，真可谓“退一步，海阔天空”。</p></li><li><p>数据兼容方面 SparkSQL 不但兼容 Hive，还可以从 RDD、parquet 文件、JSON 文件中获取数据，未来版本甚至支持获取 RDBMS 数据以及 cassandra 等 NOSQL 数据；</p></li><li><p>性能优化方面 除了采取 In-Memory Columnar Storage、byte-code generation 等优化技术外、将会引进 Cost Model 对查询进行动态评估、获取最佳物理计划等等；</p></li><li><p>组件扩展方面 无论是 SQL 的语法解析器、分析器还是优化器都可以重新定义，进行扩展。 2014 年 6 月 1 日 Shark 项目和 SparkSQL 项目的主持人 Reynold Xin 宣布：停止对 Shark 的开发，团队将所有资源放 SparkSQL 项目上，至此，Shark 的发展画上了句话，但也因此发展出两个支线：SparkSQL 和 Hive on Spark。其中SparkSQL 作为 Spark 生态的一员继续发展，而不再受限于 Hive，只是兼容 Hive；而Hive on Spark 是一个 Hive 的发展计划，该计划将 <strong>Spark 作为 Hive 的底层引擎之一</strong>，也就是说，Hive 将不再受限于一个引擎，可以采用 Map-Reduce、Tez、Spark 等引擎。 对于开发人员来讲，SparkSQL 可以<strong>简化 RDD 的开发</strong>，提高开发效率，且执行效率非常快，所以实际工作中，基本上采用的就是 SparkSQL。Spark SQL 为了简化 RDD 的开发，提高开发效率，提供了 2 个<strong>编程抽象</strong>，类似 Spark Core 中的 RDD</p></li><li><p>DataFrame</p></li><li><p>DataSet</p></li></ul><h2 id="_1-3-sparksql-特点" tabindex="-1"><a class="header-anchor" href="#_1-3-sparksql-特点"><span>1.3 SparkSQL 特点</span></a></h2><h3 id="_1-3-1-易整合" tabindex="-1"><a class="header-anchor" href="#_1-3-1-易整合"><span>1.3.1 易整合</span></a></h3><p>无缝的整合了 SQL 查询和 Spark 编程</p><h3 id="_1-3-2-统一的数据访问" tabindex="-1"><a class="header-anchor" href="#_1-3-2-统一的数据访问"><span>1.3.2 统一的数据访问</span></a></h3><p>使用相同的方式连接不同的数据源</p><h3 id="_1-3-3-兼容-hive" tabindex="-1"><a class="header-anchor" href="#_1-3-3-兼容-hive"><span>1.3.3 兼容 Hive</span></a></h3><p>在已有的仓库上直接运行 SQL 或者 HiveQL</p><h3 id="_1-3-4-标准数据连接" tabindex="-1"><a class="header-anchor" href="#_1-3-4-标准数据连接"><span>1.3.4 标准数据连接</span></a></h3><p>通过 JDBC 或者 ODBC 来连接</p><h2 id="_1-4-dataframe-是什么" tabindex="-1"><a class="header-anchor" href="#_1-4-dataframe-是什么"><span>1.4 DataFrame 是什么</span></a></h2><p>​ 在 Spark 中，DataFrame 是一种以 <strong>RDD 为基础的分布式数据集</strong>，类似于传统数据库中的二维表格。DataFrame 与 RDD 的主要区别在于，前者带有 <code>schema 元信息</code>，即 DataFrame所表示的二维表数据集的每一列都带有名称和类型。这使得 Spark SQL 得以洞察更多的结构信息，从而对藏于 DataFrame 背后的数据源以及作用于 DataFrame 之上的变换进行了针对性的优化，最终达到大幅提升运行时效率的目标。反观 RDD，由于无从得知所存数据元素的具体内部结构，Spark Core 只能在 stage 层面进行简单、通用的流水线优化。 ​ 同时，与 Hive 类似，DataFrame 也支持嵌套数据类型（struct、array 和 map）。从 API 易用性的角度上看，DataFrame API 提供的是一套高层的关系操作，比函数式的 RDD API 要更加友好，门槛更低。</p><p><img src="/simple-doc/assets/image-20250418007-C4uVNqfM.png" alt="07"></p><p>上图直观地体现了 DataFrame 和 RDD 的区别。</p><p>​ 左侧的 RDD[Person]虽然以 Person 为类型参数，但 Spark 框架本身不了解 Person 类的内部结构。而右侧的 DataFrame 却提供了详细的结构信息，使得 Spark SQL 可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame 是为数据提供了 Schema 的视图。可以把它当做数据库中的一张表来对待，DataFrame 也是懒执行的，但性能上比 RDD 要高</p><p>​ 主要原因：<strong>优化的执行计划</strong>，即查询计划通过 Spark catalyst optimiser 进行优化。比如下面一个例子:</p><p>为了说明查询优化，我们来看上图展示的人口数据分析的示例。图中构造了两个<code>DataFrame</code>，将它们 <code>join</code> 之后又做了一次 <code>filter</code> 操作。如果原封不动地执行这个执行计划，最终的执行效率是不高的。因为 <code>join</code> 是一个代价较大的操作，也可能会产生一个较大的数据集。如果我们能将 <code>filter</code> 下推到 <code>join</code> 下方，先对 <code>DataFrame</code> 进行过滤，再 <code>join</code> 过滤后的较小的结果集，便可以有效缩短执行时间。而 Spark SQL 的查询优化器正是这样做的。简而言之，逻辑查询计划优化就是一个利用<strong>基于关系代数的等价变换</strong>，将高成本的操作替换为低成本操作的过程。</p><h2 id="_1-5-dataset-是什么" tabindex="-1"><a class="header-anchor" href="#_1-5-dataset-是什么"><span>1.5 DataSet 是什么</span></a></h2><p>DataSet 是分布式数据集合。DataSet 是 Spark 1.6 中添加的一个新抽象，是 DataFrame的一个<code>扩展</code>。它提供了 RDD 的优势（强类型，使用强大的 lambda 函数的能力）以及 Spark SQL 优化执行引擎的优点。DataSet 也可以使用功能性的转换（操作map，flatMap，filter等等）。</p><ul><li><p>DataSet 是 DataFrame API 的一个扩展，是 SparkSQL 最新的数据抽象</p></li><li><p>用户友好的 API 风格，既具有类型安全检查也具有 DataFrame 的查询优化特性；</p></li><li><p>用样例类来对 DataSet 中定义数据的结构信息，样例类中每个属性的名称直接映射到DataSet 中的字段名称；</p></li><li><p>DataSet 是<code>强类型</code>的。比如可以有 DataSet[Car]，DataSet[Person]。</p></li><li><p>DataFrame 是 DataSet 的特列，DataFrame=DataSet[Row] ，所以可以通过 as 方法将DataFrame 转换为 DataSet。Row 是一个类型，跟 Car、Person 这些的类型一样，所有的表结构信息都用 Row 来表示。获取数据时需要指定顺序</p></li></ul><h1 id="第2章-sparksql-核心编程" tabindex="-1"><a class="header-anchor" href="#第2章-sparksql-核心编程"><span>第2章 SparkSQL 核心编程</span></a></h1><p>​ 本课件重点学习如何使用 <code>Spark SQL</code> 所提供的 <code>DataFrame</code> 和 <code>DataSet</code> 模型进行编程.，以及了解它们之间的关系和转换，关于具体的 SQL 书写不是我们的重点。</p><h2 id="_2-1-新的起点" tabindex="-1"><a class="header-anchor" href="#_2-1-新的起点"><span>2.1 新的起点</span></a></h2><p>​ Spark Core 中，如果想要执行应用程序，需要首先构建上下文环境对象 SparkContext，Spark SQL 其实可以理解为对 Spark Core 的一种封装，不仅仅在模型上进行了封装，上下文环境对象也进行了封装。在老的版本中，SparkSQL 提供两种 SQL 查询起始点：一个叫 SQLContext，用于 Spark自己提供的 SQL 查询；一个叫 HiveContext，用于连接 Hive 的查询。<code>SparkSession</code> 是 Spark 最新的 SQL 查询起始点，实质上是 SQLContext 和 HiveContext的组合，所以在 SQLContex 和 HiveContext 上可用的 API 在 SparkSession 上同样是可以使用的。SparkSession 内部封装了 SparkContext，所以计算实际上是由 sparkContext 完成的。当我们使用 spark-shell 的时候, spark 框架会自动的创建一个名称叫做 spark 的 SparkSession 对 象, 就像我们以前可以自动获取到一个 sc 来表示 SparkContext 对象一样</p><h2 id="_2-2-dataframe" tabindex="-1"><a class="header-anchor" href="#_2-2-dataframe"><span>2.2 DataFrame</span></a></h2><p>​ Spark SQL 的 DataFrame API 允许我们使用 DataFrame 而不用必须去注册临时表或者生成 SQL 表达式。DataFrame API 既有 transformation 操作也有 action 操作。</p><h3 id="_2-2-1-创建-dataframe" tabindex="-1"><a class="header-anchor" href="#_2-2-1-创建-dataframe"><span>2.2.1 创建 DataFrame</span></a></h3><p>​ 在 Spark SQL 中 SparkSession 是创建 DataFrame 和执行 SQL 的入口，创建 DataFrame有三种方式：</p><p>通过 Spark 的数据源进行创建；</p><p>从一个存在的 RDD 进行转换；</p><p>还可以从 Hive Table 进行查询返回。</p><ol><li>从 Spark 数据源进行创建</li></ol><ul><li>查看 Spark 支持创建文件的数据源格式</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> spark.read.</span>
<span class="line">csv <span class="token function">format</span> jdbc json load option options orc parquet schema </span>
<span class="line">table text textFile</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在 spark 的 bin/data 目录中创建 user.json 文件</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token punctuation">{</span><span class="token string">&quot;username&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;zhangsan&quot;</span>,<span class="token string">&quot;age&quot;</span>:20<span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>读取 json 文件创建 DataFrame</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> val <span class="token function">df</span> <span class="token operator">=</span> spark.read.json<span class="token punctuation">(</span><span class="token string">&quot;data/user.json&quot;</span><span class="token punctuation">)</span></span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: bigint， username: string<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>​ 注意：如果从内存中获取数据，spark 可以知道数据类型具体是什么。如果是数字，默认作为 Int 处理；但是从文件中读取的数字，不能确定是什么类型，所以用 bigint 接收，可以和Long 类型转换，但是和 Int 不能进行转换</p><ul><li>展示结果</li></ul><table><thead><tr><th>age</th><th>username</th></tr></thead><tbody><tr><td>20</td><td>zhangsan</td></tr></tbody></table><ol start="2"><li><p>从 RDD 进行转换 在后续章节中讨论</p></li><li><p>从 Hive Table 进行查询返回 在后续章节中讨论</p></li></ol><h3 id="_2-2-2-sql-语法" tabindex="-1"><a class="header-anchor" href="#_2-2-2-sql-语法"><span>2.2.2 SQL 语法</span></a></h3><p>​ SQL 语法风格是指我们查询数据的时候使用 SQL 语句来查询，这种风格的查询必须要有临时视图或者全局视图来辅助</p><ol><li>读取 JSON 文件创建 DataFrame</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val <span class="token function">df</span> <span class="token operator">=</span> spark.read.json<span class="token punctuation">(</span><span class="token string">&quot;data/user.json&quot;</span><span class="token punctuation">)</span></span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: bigint， username: string<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>对 DataFrame 创建一个临时表</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala df.createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;people&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="3"><li>通过 SQL 语句实现查询全表</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val sqlDF <span class="token operator">=</span> spark.sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM people&quot;</span><span class="token punctuation">)</span></span>
<span class="line">sqlDF: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: bigint， name: string<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li>结果展示 scala sqlDF.show</li></ol><table><thead><tr><th>age</th><th>username</th></tr></thead><tbody><tr><td>20</td><td>zhangsan</td></tr><tr><td>30</td><td>lisi</td></tr><tr><td>40</td><td>wangwu</td></tr><tr><td>​ 注意：普通临时表是 Session 范围内的，如果想应用范围内有效，可以使用全局临时表。使用全局临时表时需要全路径访问，如：global_temp.people</td><td></td></tr></tbody></table><ol start="5"><li>对于 DataFrame 创建一个全局表</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala df.createGlobalTempView<span class="token punctuation">(</span><span class="token string">&quot;people&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="6"><li>通过 SQL 语句实现查询全表</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM global_temp.people&quot;</span><span class="token punctuation">)</span>.show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>+---+--------+ | age | username | | 20 | zhangsan | | 30 | lisi | | 40 | wangwu | +---+--------+</p><h3 id="_2-2-3-dsl-语法" tabindex="-1"><a class="header-anchor" href="#_2-2-3-dsl-语法"><span>2.2.3 DSL 语法</span></a></h3><p>DataFrame 提供一个特定领域语言(domain-specific language, DSL)去管理结构化的数据。可以在 Scala, Java, Python 和 R 中使用 DSL，使用 DSL 语法风格不必去创建临时视图了</p><ol><li>创建一个 DataFrame</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val <span class="token function">df</span> <span class="token operator">=</span> spark.read.json<span class="token punctuation">(</span><span class="token string">&quot;data/user.json&quot;</span><span class="token punctuation">)</span></span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: bigint， name: string<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>查看 DataFrame 的 Schema 信息</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> df.printSchema</span>
<span class="line">root</span>
<span class="line"><span class="token operator">|</span>-- age: Long <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">|</span>-- username: string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>只查看&quot;username&quot;列数据，</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> df.select<span class="token punctuation">(</span><span class="token string">&quot;username&quot;</span><span class="token punctuation">)</span>.show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">+--------+</span>
<span class="line"><span class="token operator">|</span>username<span class="token operator">|</span></span>
<span class="line">+--------+</span>
<span class="line"><span class="token operator">|</span>zhangsan<span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> lisi<span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> wangwu<span class="token operator">|</span></span>
<span class="line">+--------+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li>查看&quot;username&quot;列数据以及&quot;age+1&quot;数据 注意:涉及到运算的时候, 每列都必须使用$, 或者采用引号表达式：单引号+字段名</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> df.select<span class="token punctuation">(</span>$<span class="token string">&quot;username&quot;</span>,$<span class="token string">&quot;age&quot;</span> + <span class="token number">1</span><span class="token punctuation">)</span>.show</span>
<span class="line">scala<span class="token operator">&gt;</span> df.select<span class="token punctuation">(</span><span class="token string">&#39;username, &#39;</span>age + <span class="token number">1</span><span class="token punctuation">)</span>.show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">scala<span class="token operator">&gt;</span> df.select<span class="token punctuation">(</span><span class="token string">&#39;username, &#39;</span>age + <span class="token number">1</span> as <span class="token string">&quot;newage&quot;</span><span class="token punctuation">)</span>.show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"> +--------+---------+</span>
<span class="line"><span class="token operator">|</span> username <span class="token operator">|</span> <span class="token punctuation">(</span>age + <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> zhangsan <span class="token operator">|</span> <span class="token number">21</span>   <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> lisi     <span class="token operator">|</span> <span class="token number">31</span>   <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> wangwu   <span class="token operator">|</span> <span class="token number">41</span>   <span class="token operator">|</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="5"><li>查看&quot;age&quot;大于&quot;30&quot;的数据</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> df.filter<span class="token punctuation">(</span>$<span class="token string">&quot;age&quot;</span><span class="token number">30</span><span class="token punctuation">)</span>.show</span>
<span class="line">+---+---------+</span>
<span class="line"><span class="token operator">|</span> age  <span class="token operator">|</span> username <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">40</span>   <span class="token operator">|</span> wangwu <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> ---- <span class="token operator">|</span> ------ <span class="token operator">|</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="6"><li>按照&quot;age&quot;分组，查看数据条数</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala<span class="token operator">&gt;</span> df.groupBy<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span>.count.show</span>
<span class="line"> +---+-----+</span>
<span class="line"><span class="token operator">|</span> age  <span class="token operator">|</span> count <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">20</span>   <span class="token operator">|</span> <span class="token number">1</span>    <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">30</span>   <span class="token operator">|</span> <span class="token number">1</span>    <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">40</span>   <span class="token operator">|</span> <span class="token number">1</span>    <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> ---- <span class="token operator">|</span> ---- <span class="token operator">|</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-4-rdd-转换为-dataframe" tabindex="-1"><a class="header-anchor" href="#_2-2-4-rdd-转换为-dataframe"><span>2.2.4 RDD 转换为 DataFrame</span></a></h3><p>​ 在 IDEA 中开发程序时，如果需要 RDD 与 DF 或者 DS 之间互相操作，那么需要引入<strong>import spark.implicits._</strong> 这里的 spark 不是 Scala 中的包名，而是创建的 sparkSession 对象的变量名称，所以必须先创建 SparkSession 对象再导入。这里的 spark 对象不能使用 var 声明，因为 Scala 只支持val 修饰的对象的引入。spark-shell 中无需导入，自动完成此操作。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val idRDD <span class="token operator">=</span> sc.textFile<span class="token punctuation">(</span><span class="token string">&quot;data/id.txt&quot;</span><span class="token punctuation">)</span></span>
<span class="line">scala idRDD.toDF<span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">)</span>.show</span>
<span class="line">+---+</span>
<span class="line"><span class="token operator">|</span> <span class="token function">id</span><span class="token operator">|</span></span>
<span class="line">+---+</span>
<span class="line"><span class="token operator">|</span> <span class="token number">1</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">2</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">3</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">4</span><span class="token operator">|</span></span>
<span class="line">+---+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>实际开发中，一般通过样例类将 RDD 转换为 DataFrame</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"> scala <span class="token keyword">case</span> class User<span class="token punctuation">(</span>name:String, age:Int<span class="token punctuation">)</span></span>
<span class="line"> defined class User</span>
<span class="line"> scala sc.makeRDD<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;zhangsan&quot;<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;lisi&quot;<span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>.map<span class="token punctuation">(</span>t<span class="token operator">=</span>User<span class="token punctuation">(</span>t._1,t._2<span class="token punctuation">))</span>.toDF.show</span>
<span class="line"> +--------+---+</span>
<span class="line"> <span class="token operator">|</span> name<span class="token operator">|</span>age<span class="token operator">|</span></span>
<span class="line"> +--------+---+</span>
<span class="line"><span class="token operator">|</span> zhangsan <span class="token operator">|</span> <span class="token number">30</span>   <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> -------- <span class="token operator">|</span> ---- <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> lisi     <span class="token operator">|</span> <span class="token number">40</span>   <span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> ----     <span class="token operator">|</span> ---- <span class="token operator">|</span></span>
<span class="line">+--------+---+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-5-dataframe-转换为-rdd" tabindex="-1"><a class="header-anchor" href="#_2-2-5-dataframe-转换为-rdd"><span>2.2.5 DataFrame 转换为 RDD</span></a></h3><p>DataFrame 其实就是对 RDD 的封装，所以可以直接获取内部的 RDD</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line">scala <span class="token keyword">val</span> df <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;lisi&quot;</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>t<span class="token operator">=</span>User<span class="token punctuation">(</span>t<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDF</span>
<span class="line">df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> age<span class="token operator">:</span> int<span class="token punctuation">]</span></span>
<span class="line">scala <span class="token keyword">val</span> rdd <span class="token operator">=</span> df<span class="token punctuation">.</span>rdd</span>
<span class="line">rdd<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span> at rdd at <span class="token operator">&lt;</span>console<span class="token operator">:</span><span class="token number">25</span></span>
<span class="line">scala <span class="token keyword">val</span> array <span class="token operator">=</span> rdd<span class="token punctuation">.</span>collect</span>
<span class="line">array<span class="token operator">:</span> Array<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">[</span>zhangsan<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>lisi<span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：此时得到的 RDD 存储类型为 Row</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala array<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">res28: org.apache.spark.sql.Row <span class="token operator">=</span> <span class="token punctuation">[</span>zhangsan,30<span class="token punctuation">]</span></span>
<span class="line">scala array<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">res29: Any <span class="token operator">=</span> zhangsan</span>
<span class="line">scala array<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>.getAs<span class="token punctuation">[</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span></span>
<span class="line">res30: String <span class="token operator">=</span> zhangsan</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-3-dataset" tabindex="-1"><a class="header-anchor" href="#_2-3-dataset"><span>2.3 DataSet</span></a></h2><p>DataSet 是具有强类型的数据集合，需要提供对应的类型信息。</p><h3 id="_2-3-1-创建-dataset" tabindex="-1"><a class="header-anchor" href="#_2-3-1-创建-dataset"><span>2.3.1 创建 DataSet</span></a></h3><p>1） 使用样例类序列创建 DataSet</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala <span class="token keyword">case</span> class Person<span class="token punctuation">(</span>name: String, age: Long<span class="token punctuation">)</span></span>
<span class="line">defined class Person</span>
<span class="line">scala val caseClassDS <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Person<span class="token punctuation">(</span><span class="token string">&quot;zhangsan&quot;</span>,2<span class="token punctuation">))</span>.toDS<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">caseClassDS: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: Long<span class="token punctuation">]</span></span>
<span class="line">scala caseClassDS.show</span>
<span class="line">+---------+---+</span>
<span class="line"><span class="token operator">|</span> name<span class="token operator">|</span>age<span class="token operator">|</span></span>
<span class="line">+---------+---+</span>
<span class="line"><span class="token operator">|</span> zhangsan<span class="token operator">|</span> <span class="token number">2</span><span class="token operator">|</span></span>
<span class="line">+---------+---+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2） 使用基本类型的序列创建 DataSet</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val ds <span class="token operator">=</span> Seq<span class="token punctuation">(</span><span class="token number">1,2</span>,3,4,5<span class="token punctuation">)</span>.toDS</span>
<span class="line">ds: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>Int<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value: int<span class="token punctuation">]</span></span>
<span class="line">scala ds.show</span>
<span class="line">+-----+</span>
<span class="line"><span class="token operator">|</span>value<span class="token operator">|</span></span>
<span class="line">+-----+</span>
<span class="line"><span class="token operator">|</span> <span class="token number">1</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">2</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">3</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">4</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">5</span><span class="token operator">|</span></span>
<span class="line">+-----+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：在实际使用的时候，很少用到把序列转换成DataSet，更多的是通过RDD来得到DataSet</p><h3 id="_2-3-2-rdd-转换为-dataset" tabindex="-1"><a class="header-anchor" href="#_2-3-2-rdd-转换为-dataset"><span>2.3.2 RDD 转换为 DataSet</span></a></h3><p>​ SparkSQL 能够自动将包含有 case 类的 RDD 转换成 DataSet，case 类定义了 table 的结构，case 类属性通过反射变成了表的列名。Case 类可以包含诸如 Seq 或者 Array 等复杂的结构。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala <span class="token keyword">case</span> class User<span class="token punctuation">(</span>name:String, age:Int<span class="token punctuation">)</span></span>
<span class="line">defined class User</span>
<span class="line">scala sc.makeRDD<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;zhangsan&quot;<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;lisi&quot;<span class="token punctuation">,</span><span class="token number">49</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>.map<span class="token punctuation">(</span>t<span class="token operator">=</span>User<span class="token punctuation">(</span>t._1, </span>
<span class="line">t._2<span class="token punctuation">))</span>.toDS</span>
<span class="line">res11: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-3-dataset-转换为-rdd" tabindex="-1"><a class="header-anchor" href="#_2-3-3-dataset-转换为-rdd"><span>2.3.3 DataSet 转换为 RDD</span></a></h3><p>DataSet 其实也是对 RDD 的封装，所以可以直接获取内部的 RDD</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala <span class="token keyword">case</span> class User<span class="token punctuation">(</span>name:String, age:Int<span class="token punctuation">)</span></span>
<span class="line">defined class User</span>
<span class="line">scala sc.makeRDD<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;zhangsan&quot;<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;lisi&quot;<span class="token punctuation">,</span><span class="token number">49</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>.map<span class="token punctuation">(</span>t<span class="token operator">=</span>User<span class="token punctuation">(</span>t._1, t._2<span class="token punctuation">))</span>.toDS</span>
<span class="line">res11: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line">scala val rdd <span class="token operator">=</span> res11.rdd</span>
<span class="line">rdd: org.apache.spark.rdd.RDD<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">51</span><span class="token punctuation">]</span> at rdd at </span>
<span class="line"><span class="token operator">&lt;</span>console:25</span>
<span class="line">scala rdd.collect</span>
<span class="line">res12: Array<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>User<span class="token punctuation">(</span>zhangsan,30<span class="token punctuation">)</span>, User<span class="token punctuation">(</span>lisi,49<span class="token punctuation">))</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-4-dataframe-和-dataset-转换" tabindex="-1"><a class="header-anchor" href="#_2-4-dataframe-和-dataset-转换"><span>2.4 DataFrame 和 DataSet 转换</span></a></h2><p>DataFrame 其实是 DataSet 的特例，所以它们之间是可以互相转换的。</p><ul><li>DataFrame 转换为 DataSet</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala <span class="token keyword">case</span> class User<span class="token punctuation">(</span>name:String, age:Int<span class="token punctuation">)</span></span>
<span class="line">defined class User</span>
<span class="line">scala val <span class="token function">df</span> <span class="token operator">=</span> sc.makeRDD<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;zhangsan&quot;<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> </span>
<span class="line"><span class="token punctuation">(</span>&quot;lisi&quot;<span class="token punctuation">,</span><span class="token number">49</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>.toDF<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span>,<span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span></span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line">scala val ds <span class="token operator">=</span> df.as<span class="token punctuation">[</span>User<span class="token punctuation">]</span></span>
<span class="line">ds: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>DataSet 转换为 DataFrame</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val ds <span class="token operator">=</span> df.as<span class="token punctuation">[</span>User<span class="token punctuation">]</span></span>
<span class="line">ds: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line">scala val <span class="token function">df</span> <span class="token operator">=</span> ds.toDF</span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: int<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-5-rdd、dataframe、dataset-三者的关系" tabindex="-1"><a class="header-anchor" href="#_2-5-rdd、dataframe、dataset-三者的关系"><span>2.5 RDD、DataFrame、DataSet 三者的关系</span></a></h2><p>​ 在 SparkSQL 中 Spark 为我们提供了两个新的抽象，分别是 DataFrame 和 DataSet。他们和 RDD 有什么区别呢？首先从版本的产生上来看：</p><ul><li>Spark1.0 = RDD</li><li>Spark1.3 = DataFrame</li><li>Spark1.6 = Dataset 如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同是的他们的执行效率和执行方式。在后期的 Spark 版本中，DataSet 有可能会逐步取代 RDD和 DataFrame 成为唯一的 API 接口。</li></ul><h3 id="_2-5-1-三者的共性" tabindex="-1"><a class="header-anchor" href="#_2-5-1-三者的共性"><span>2.5.1 三者的共性</span></a></h3><ul><li><p>RDD、DataFrame、DataSet 全都是 spark 平台下的分布式弹性数据集，为处理超大型数据提供便利;</p></li><li><p>三者都有惰性机制，在进行创建、转换，如 map 方法时，不会立即执行，只有在遇到Action 如 foreach 时，三者才会开始遍历运算;</p></li><li><p>三者有许多共同的函数，如 filter，排序等;</p></li><li><p>在对 DataFrame 和 Dataset 进行操作许多操作都需要这个包:import spark.implicits._（在创建好 SparkSession 对象后尽量直接导入）</p></li><li><p>三者都会根据 Spark 的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出</p></li><li><p>三者都有 partition 的概念</p></li><li><p>DataFrame 和 DataSet 均可使用模式匹配获取各个字段的值和类型</p></li></ul><h3 id="_2-5-2-三者的区别" tabindex="-1"><a class="header-anchor" href="#_2-5-2-三者的区别"><span>2.5.2 三者的区别</span></a></h3><ol><li>RDD</li></ol><ul><li>RDD 一般和 spark mllib 同时使用</li><li>RDD 不支持 sparksql 操作</li></ul><ol start="2"><li>DataFrame</li></ol><ul><li><p>与 RDD 和 Dataset 不同，DataFrame 每一行的类型固定为 Row，每一列的值没法直 接访问，只有通过解析才能获取各个字段的值</p></li><li><p>DataFrame 与 DataSet 一般不与 spark mllib 同时使用</p></li><li><p>DataFrame 与 DataSet 均支持 SparkSQL 的操作，比如 select，groupby 之类，还能注册临时表/视窗，进行 sql 语句操作</p></li><li><p>DataFrame 与 DataSet 支持一些特别方便的保存方式，比如保存成 csv，可以带上表头，这样每一列的字段名一目了然(后面专门讲解)</p></li></ul><ol start="3"><li>DataSet</li></ol><ul><li>Dataset 和 DataFrame 拥有完全相同的成员函数，区别只是每一行的数据类型不同。DataFrame 其实就是 DataSet 的一个特例 type DataFrame = Dataset[Row]</li><li>DataFrame 也可以叫 Dataset[Row],每一行的类型是 Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的 getAS 方法或者共性中的第七条提到的模式匹配拿出特定字段。而 Dataset 中，每一行是什么类型是不一定的，在自定义了 case class 之后可以很自由的获得每一行的信息</li></ul><h3 id="_2-5-3-三者的互相转换" tabindex="-1"><a class="header-anchor" href="#_2-5-3-三者的互相转换"><span>2.5.3 三者的互相转换</span></a></h3><p>![image-20210219141759152](spark sql-尚.assets/image-20210219141759152.png)</p><h2 id="_2-6-idea-开发-sparksql" tabindex="-1"><a class="header-anchor" href="#_2-6-idea-开发-sparksql"><span>2.6 IDEA 开发 SparkSQL</span></a></h2><p>实际开发中，都是使用 IDEA 进行开发的。</p><h3 id="_2-6-1-添加依赖" tabindex="-1"><a class="header-anchor" href="#_2-6-1-添加依赖"><span>2.6.1 添加依赖</span></a></h3><div class="language-xml line-numbers-mode" data-highlighter="prismjs" data-ext="xml"><pre><code><span class="line">&lt;dependency</span>
<span class="line">    &lt;groupIdorg.apache.spark&lt;/groupId</span>
<span class="line">    &lt;artifactIdspark-sql_2.12&lt;/artifactId</span>
<span class="line">    &lt;version3.0.0&lt;/version</span>
<span class="line">&lt;/dependency</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-6-2-代码实现" tabindex="-1"><a class="header-anchor" href="#_2-6-2-代码实现"><span>2.6.2 代码实现</span></a></h3><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">object</span> SparkSQL01_Demo <span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token comment">//创建上下文环境配置对象</span></span>
<span class="line">        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;SparkSQL01_Demo&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//创建 SparkSession 对象</span></span>
<span class="line">        <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//RDD=DataFrame=DataSet 转换需要引入隐式转换规则，否则无法转换</span></span>
<span class="line">        <span class="token comment">//spark 不是包名，是上下文环境对象名</span></span>
<span class="line">        <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</span>
<span class="line">        <span class="token comment">//读取 json 文件 创建 DataFrame {&quot;username&quot;: &quot;lisi&quot;,&quot;age&quot;: 18}</span></span>
<span class="line">        <span class="token keyword">val</span> df<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;input/test.json&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//df.show()</span></span>
<span class="line">        <span class="token comment">//SQL 风格语法</span></span>
<span class="line">        df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//spark.sql(&quot;select avg(age) from user&quot;).show</span></span>
<span class="line">        <span class="token comment">//DSL 风格语法</span></span>
<span class="line">        <span class="token comment">//df.select(&quot;username&quot;,&quot;age&quot;).show()</span></span>
<span class="line">        <span class="token comment">//RDD=DataFrame=DataSet</span></span>
<span class="line">        <span class="token comment">//RDD</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">&quot;lisi&quot;</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">&quot;wangwu&quot;</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//DataFrame</span></span>
<span class="line">        <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//df1.show()</span></span>
<span class="line">        <span class="token comment">//DateSet</span></span>
<span class="line">        <span class="token keyword">val</span> ds1<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> df1<span class="token punctuation">.</span>as<span class="token punctuation">[</span>User<span class="token punctuation">]</span></span>
<span class="line">        <span class="token comment">//ds1.show()</span></span>
<span class="line">        <span class="token comment">//DataSet=DataFrame=RDD</span></span>
<span class="line">        <span class="token comment">//DataFrame</span></span>
<span class="line">        <span class="token keyword">val</span> df2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> ds1<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//RDD 返回的 RDD 类型为 Row，里面提供的 getXXX 方法可以获取字段值，类似 jdbc 处理结果集，但是索引从 0 开始</span></span>
<span class="line">        <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> df2<span class="token punctuation">.</span>rdd</span>
<span class="line">        <span class="token comment">//rdd2.foreach(a=println(a.getString(1)))</span></span>
<span class="line">        <span class="token comment">//RDD=DataSet</span></span>
<span class="line">        rdd1<span class="token punctuation">.</span>map<span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">case</span> <span class="token punctuation">(</span>id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span><span class="token operator">=</span>User<span class="token punctuation">(</span>id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">}</span><span class="token punctuation">.</span>toDS<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment">//DataSet==RDD</span></span>
<span class="line">        ds1<span class="token punctuation">.</span>rdd</span>
<span class="line">        <span class="token comment">//释放资源</span></span>
<span class="line">        spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span> </span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"><span class="token keyword">case</span> <span class="token keyword">class</span> User<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-7-用户自定义函数" tabindex="-1"><a class="header-anchor" href="#_2-7-用户自定义函数"><span>2.7 用户自定义函数</span></a></h2><p>用户可以通过 spark.udf 功能添加自定义函数，实现自定义功能。</p><h3 id="_2-7-1-udf" tabindex="-1"><a class="header-anchor" href="#_2-7-1-udf"><span>2.7.1 UDF</span></a></h3><ol><li>创建 DataFrame</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala val <span class="token function">df</span> <span class="token operator">=</span> spark.read.json<span class="token punctuation">(</span><span class="token string">&quot;data/user.json&quot;</span><span class="token punctuation">)</span></span>
<span class="line">df: org.apache.spark.sql.DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: bigint， username: string<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>注册 UDF</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala spark.udf.register<span class="token punctuation">(</span><span class="token string">&quot;addName&quot;</span>,<span class="token punctuation">(</span>x:String<span class="token punctuation">)</span><span class="token operator">=</span> <span class="token string">&quot;Name:&quot;</span>+x<span class="token punctuation">)</span></span>
<span class="line">res9: org.apache.spark.sql.expressions.UserDefinedFunction <span class="token operator">=</span> </span>
<span class="line">UserDefinedFunction<span class="token punctuation">(</span><span class="token operator">&lt;</span>function1,StringType,Some<span class="token punctuation">(</span>List<span class="token punctuation">(</span>StringType<span class="token punctuation">))</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>创建临时表</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala df.createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;people&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ol start="4"><li>应用 UDF</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;Select addName(name),age from people&quot;</span><span class="token punctuation">)</span>.show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_2-7-2-udaf" tabindex="-1"><a class="header-anchor" href="#_2-7-2-udaf"><span>2.7.2 UDAF</span></a></h3><p>​ 强类型的 Dataset 和弱类型的 DataFrame 都提供了相关的聚合函数， 如 count()，countDistinct()，avg()，max()，min()。除此之外，用户可以设定自己的自定义<code>聚合函数</code>。通过继承 UserDefinedAggregateFunction 来实现用户自定义弱类型聚合函数。从 Spark3.0 版本后，UserDefinedAggregateFunction 已经不推荐使用了。可以统一采用强类型聚合函数Aggregator</p><p>需求：计算平均工资 一个需求可以采用很多种不同的方法实现需求</p><ol><li>实现方式 - RDD</li></ol><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;app&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">val</span> res<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;lisi&quot;</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;wangw&quot;</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">case</span> <span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token punctuation">(</span>age<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">.</span>reduce <span class="token punctuation">{</span></span>
<span class="line">    <span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token punctuation">(</span>t1<span class="token punctuation">.</span>_1 <span class="token operator">+</span> t2<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t1<span class="token punctuation">.</span>_2 <span class="token operator">+</span> t2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line">println<span class="token punctuation">(</span>res<span class="token punctuation">.</span>_1<span class="token operator">/</span>res<span class="token punctuation">.</span>_2<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">// 关闭连接</span></span>
<span class="line">sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>实现方式 - 累加器</li></ol><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">class</span> MyAC <span class="token keyword">extends</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">var</span> sum<span class="token operator">:</span><span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    <span class="token keyword">var</span> count<span class="token operator">:</span><span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> isZero<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">return</span> sum <span class="token operator">==</span><span class="token number">0</span> <span class="token operator">&amp;&amp;</span> count <span class="token operator">==</span> <span class="token number">0</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">val</span> newMyAc <span class="token operator">=</span> <span class="token keyword">new</span> MyAC</span>
<span class="line">        newMyAc<span class="token punctuation">.</span>sum <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>sum</span>
<span class="line">        newMyAc<span class="token punctuation">.</span>count <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>count</span>
<span class="line">        newMyAc</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        sum <span class="token operator">=</span><span class="token number">0</span></span>
<span class="line">        count <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>v<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        sum <span class="token operator">+=</span> v</span>
<span class="line">        count <span class="token operator">+=</span> <span class="token number">1</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>other<span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        other <span class="token keyword">match</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token keyword">case</span> o<span class="token operator">:</span>MyAC<span class="token operator">=</span><span class="token punctuation">{</span></span>
<span class="line">                sum <span class="token operator">+=</span> o<span class="token punctuation">.</span>sum</span>
<span class="line">                count <span class="token operator">+=</span> o<span class="token punctuation">.</span>count</span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">            <span class="token keyword">case</span> _<span class="token operator">=</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> value<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> sum<span class="token operator">/</span>count</span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>实现方式 - UDAF - 弱类型</li></ol><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token comment">/*</span>
<span class="line">定义类继承 UserDefinedAggregateFunction，并重写其中方法</span>
<span class="line">*/</span></span>
<span class="line"><span class="token keyword">class</span> MyAveragUDAF <span class="token keyword">extends</span> UserDefinedAggregateFunction <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// 聚合函数输入参数的数据类型</span></span>
<span class="line">    <span class="token keyword">def</span> inputSchema<span class="token operator">:</span> StructType <span class="token operator">=</span> StructType<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span>IntegerType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token comment">// 聚合函数缓冲区中值的数据类型(age,count)</span></span>
<span class="line">    <span class="token keyword">def</span> bufferSchema<span class="token operator">:</span> StructType <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        StructType<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span><span class="token string">&quot;sum&quot;</span><span class="token punctuation">,</span>LongType<span class="token punctuation">)</span><span class="token punctuation">,</span>StructField<span class="token punctuation">(</span><span class="token string">&quot;count&quot;</span><span class="token punctuation">,</span>LongType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 函数返回值的数据类型</span></span>
<span class="line">    <span class="token keyword">def</span> dataType<span class="token operator">:</span> DataType <span class="token operator">=</span> DoubleType</span>
<span class="line">    <span class="token comment">// 稳定性：对于相同的输入是否一直返回相同的输出。</span></span>
<span class="line">    <span class="token keyword">def</span> deterministic<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span></span>
<span class="line">    <span class="token comment">// 函数缓冲区初始化</span></span>
<span class="line">    <span class="token keyword">def</span> initialize<span class="token punctuation">(</span>buffer<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token comment">// 存年龄的总和</span></span>
<span class="line">        buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0L</span></span>
<span class="line">        <span class="token comment">// 存年龄的个数</span></span>
<span class="line">        buffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0L</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 更新缓冲区中的数据</span></span>
<span class="line">    <span class="token keyword">def</span> update<span class="token punctuation">(</span>buffer<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">,</span>input<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>input<span class="token punctuation">.</span>isNullAt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span></span>
<span class="line">            buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> input<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">            buffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 合并缓冲区</span></span>
<span class="line">    <span class="token keyword">def</span> merge<span class="token punctuation">(</span>buffer1<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">,</span>buffer2<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        buffer1<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer1<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> buffer2<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">        buffer1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer1<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> buffer2<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">// 计算最终结果</span></span>
<span class="line">    <span class="token keyword">def</span> evaluate<span class="token punctuation">(</span>buffer<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDouble <span class="token operator">/</span> buffer<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line">。。。</span>
<span class="line"><span class="token comment">//创建聚合函数</span></span>
<span class="line"><span class="token keyword">var</span> myAverage <span class="token operator">=</span> <span class="token keyword">new</span> MyAveragUDAF</span>
<span class="line"><span class="token comment">//在 spark 中注册聚合函数</span></span>
<span class="line">spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;avgAge&quot;</span><span class="token punctuation">,</span>myAverage<span class="token punctuation">)</span></span>
<span class="line">spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select avgAge(age) from user&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li>实现方式 - UDAF - 强类型</li></ol><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token comment">//输入数据类型</span></span>
<span class="line"><span class="token keyword">case</span> <span class="token keyword">class</span> User01<span class="token punctuation">(</span>username<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//缓存类型</span></span>
<span class="line"><span class="token keyword">case</span> <span class="token keyword">class</span> AgeBuffer<span class="token punctuation">(</span><span class="token keyword">var</span> sum<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token keyword">var</span> count<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">/**</span>
<span class="line">* 定义类继承 org.apache.spark.sql.expressions.Aggregator</span>
<span class="line">* 重写类中的方法</span>
<span class="line">*/</span></span>
<span class="line"><span class="token keyword">class</span> MyAveragUDAF1 <span class="token keyword">extends</span> Aggregator<span class="token punctuation">[</span>User01<span class="token punctuation">,</span>AgeBuffer<span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> zero<span class="token operator">:</span> AgeBuffer <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        AgeBuffer<span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span><span class="token number">0L</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> reduce<span class="token punctuation">(</span>b<span class="token operator">:</span> AgeBuffer<span class="token punctuation">,</span> a<span class="token operator">:</span> User01<span class="token punctuation">)</span><span class="token operator">:</span> AgeBuffer <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        b<span class="token punctuation">.</span>sum <span class="token operator">=</span> b<span class="token punctuation">.</span>sum <span class="token operator">+</span> a<span class="token punctuation">.</span>age</span>
<span class="line">        b<span class="token punctuation">.</span>count <span class="token operator">=</span> b<span class="token punctuation">.</span>count <span class="token operator">+</span> <span class="token number">1</span></span>
<span class="line">        b</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>b1<span class="token operator">:</span> AgeBuffer<span class="token punctuation">,</span> b2<span class="token operator">:</span> AgeBuffer<span class="token punctuation">)</span><span class="token operator">:</span> AgeBuffer <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        b1<span class="token punctuation">.</span>sum <span class="token operator">=</span> b1<span class="token punctuation">.</span>sum <span class="token operator">+</span> b2<span class="token punctuation">.</span>sum</span>
<span class="line">        b1<span class="token punctuation">.</span>count <span class="token operator">=</span> b1<span class="token punctuation">.</span>count <span class="token operator">+</span> b2<span class="token punctuation">.</span>count</span>
<span class="line">        b1</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> finish<span class="token punctuation">(</span>buff<span class="token operator">:</span> AgeBuffer<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        buff<span class="token punctuation">.</span>sum<span class="token punctuation">.</span>toDouble<span class="token operator">/</span>buff<span class="token punctuation">.</span>count</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token comment">//DataSet 默认额编解码器，用于序列化，固定写法</span></span>
<span class="line">    <span class="token comment">//自定义类型就是 product 自带类型根据类型选择</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> bufferEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span>AgeBuffer<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        Encoders<span class="token punctuation">.</span>product</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> outputEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        Encoders<span class="token punctuation">.</span>scalaDouble</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line">。。。</span>
<span class="line"></span>
<span class="line"><span class="token comment">//封装为 DataSet</span></span>
<span class="line"><span class="token keyword">val</span> ds<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>User01<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>as<span class="token punctuation">[</span>User01<span class="token punctuation">]</span></span>
<span class="line"><span class="token comment">//创建聚合函数</span></span>
<span class="line"><span class="token keyword">var</span> myAgeUdaf1 <span class="token operator">=</span> <span class="token keyword">new</span> MyAveragUDAF1</span>
<span class="line"><span class="token comment">//将聚合函数转换为查询的列</span></span>
<span class="line"><span class="token keyword">val</span> col<span class="token operator">:</span> TypedColumn<span class="token punctuation">[</span>User01<span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> myAgeUdaf1<span class="token punctuation">.</span>toColumn</span>
<span class="line"><span class="token comment">//查询</span></span>
<span class="line">ds<span class="token punctuation">.</span>select<span class="token punctuation">(</span>col<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//Spark3.0 版本可以采用强类型的 Aggregator 方式代替 UserDefinedAggregateFunction </span></span>
<span class="line"><span class="token comment">// TODO 创建 UDAF 函数</span></span>
<span class="line"><span class="token keyword">val</span> udaf <span class="token operator">=</span> <span class="token keyword">new</span> MyAvgAgeUDAF</span>
<span class="line"><span class="token comment">// TODO 注册到 SparkSQL 中</span></span>
<span class="line">spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;avgAge&quot;</span><span class="token punctuation">,</span> functions<span class="token punctuation">.</span>udaf<span class="token punctuation">(</span>udaf<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">// TODO 在 SQL 中使用聚合函数</span></span>
<span class="line"><span class="token comment">// 定义用户的自定义聚合函数</span></span>
<span class="line">spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select avgAge(age) from user&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show</span>
<span class="line"><span class="token comment">// **************************************************</span></span>
<span class="line"><span class="token keyword">case</span> <span class="token keyword">class</span> Buff<span class="token punctuation">(</span> <span class="token keyword">var</span> sum<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token keyword">var</span> cnt<span class="token operator">:</span><span class="token builtin">Long</span> <span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">// totalage, count</span></span>
<span class="line"><span class="token keyword">class</span> MyAvgAgeUDAF <span class="token keyword">extends</span> Aggregator<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Buff<span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">{</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> zero<span class="token operator">:</span> Buff <span class="token operator">=</span> Buff<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> reduce<span class="token punctuation">(</span>b<span class="token operator">:</span> Buff<span class="token punctuation">,</span> a<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> Buff <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        b<span class="token punctuation">.</span>sum <span class="token operator">+=</span> a</span>
<span class="line">        b<span class="token punctuation">.</span>cnt <span class="token operator">+=</span> <span class="token number">1</span></span>
<span class="line">        b</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>b1<span class="token operator">:</span> Buff<span class="token punctuation">,</span> b2<span class="token operator">:</span> Buff<span class="token punctuation">)</span><span class="token operator">:</span> Buff <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        b1<span class="token punctuation">.</span>sum <span class="token operator">+=</span> b2<span class="token punctuation">.</span>sum</span>
<span class="line">        b1<span class="token punctuation">.</span>cnt <span class="token operator">+=</span> b2<span class="token punctuation">.</span>cnt</span>
<span class="line">        b1</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> finish<span class="token punctuation">(</span>reduction<span class="token operator">:</span> Buff<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">        reduction<span class="token punctuation">.</span>sum<span class="token punctuation">.</span>toDouble<span class="token operator">/</span>reduction<span class="token punctuation">.</span>cnt</span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> bufferEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span>Buff<span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product</span>
<span class="line">    <span class="token keyword">override</span> <span class="token keyword">def</span> outputEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>scalaDouble</span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-8-数据的加载和保存" tabindex="-1"><a class="header-anchor" href="#_2-8-数据的加载和保存"><span>2.8 数据的加载和保存</span></a></h2><h3 id="_2-8-1-通用的加载和保存方式" tabindex="-1"><a class="header-anchor" href="#_2-8-1-通用的加载和保存方式"><span>2.8.1 通用的加载和保存方式</span></a></h3><p>​ SparkSQL 提供了通用的保存数据和数据加载的方式。这里的通用指的是使用相同的API，根据不同的参数读取和保存不同格式的数据，SparkSQL 默认读取和保存的文件格式为 parquet</p><ol><li>加载数据 spark.read.load 是加载数据的通用方法 scala spark.read. csv format jdbc json load option options orc parquet schema table text textFile 如果读取不同格式的数据，可以对不同的数据格式进行设定 scala spark.read.format(&quot;…&quot;)[.option(&quot;…&quot;)].load(&quot;…&quot;)</li></ol><ul><li><p>format(&quot;…&quot;)：指定加载的数据类型，包括&quot;csv&quot;、&quot;jdbc&quot;、&quot;json&quot;、&quot;orc&quot;、&quot;parquet&quot;和&quot;textFile&quot;。</p></li><li><p>load(&quot;…&quot;)：在&quot;csv&quot;、&quot;jdbc&quot;、&quot;json&quot;、&quot;orc&quot;、&quot;parquet&quot;和&quot;textFile&quot;格式下需要传入加载数据的<code>路径</code>。</p></li><li><p>option(&quot;…&quot;)：在&quot;jdbc&quot;格式下需要传入 JDBC 相应参数，url、user、password 和 dbtable我们前面都是使用 read API 先把文件加载到 DataFrame 然后再查询，其实，我们也可以直接在文件上进行查询: 文件格式.<code>文件路径</code> scalaspark.sql(&quot;select * from json.<code>/opt/module/data/user.json</code>&quot;).show</p></li></ul><ol start="2"><li>保存数据 df.write.save 是保存数据的通用方法 scaladf.write. csv jdbc json orc parquet textFile… … 如果保存不同格式的数据，可以对不同的数据格式进行设定 scaladf.write.format(&quot;…&quot;)[.option(&quot;…&quot;)].save(&quot;…&quot;)</li></ol><ul><li><p>format(&quot;…&quot;)：指定保存的数据类型，包括&quot;csv&quot;、&quot;jdbc&quot;、&quot;json&quot;、&quot;orc&quot;、&quot;parquet&quot;和&quot;textFile&quot;。</p></li><li><p>save (&quot;…&quot;)：在&quot;csv&quot;、&quot;orc&quot;、&quot;parquet&quot;和&quot;textFile&quot;格式下需要传入保存数据的路径。</p></li><li><p>option(&quot;…&quot;)：在&quot;jdbc&quot;格式下需要传入 JDBC 相应参数，url、user、password 和 dbtable保存操作可以使用 SaveMode, 用来指明如何处理数据，使用 mode()方法来设置。有一点很重要: 这些 <strong>SaveMode 都是没有加锁的, 也不是原子操作</strong>。 SaveMode 是一个枚举类，其中的常量包括： Scala/Java Any Language Meaning SaveMode.ErrorIfExists(default) &quot;error&quot;(default) 如果文件已经存在则抛出异常 SaveMode.Append &quot;append&quot; 如果文件已经存在则追加 SaveMode.Overwrite &quot;overwrite&quot; 如果文件已经存在则覆盖 SaveMode.Ignore &quot;ignore&quot; 如果文件已经存在则忽略 df.write.mode(&quot;append&quot;).json(&quot;/opt/module/data/output&quot;)</p></li></ul><h3 id="_2-8-2-parquet" tabindex="-1"><a class="header-anchor" href="#_2-8-2-parquet"><span>2.8.2 Parquet</span></a></h3><p>​ Spark SQL 的默认数据源为 Parquet 格式。Parquet 是一种能够有效存储嵌套数据的列式存储格式。数据源为 Parquet 文件时，Spark SQL 可以方便的执行所有的操作，不需要使用 format。修改配置项 spark.sql.sources.default，可修改默认数据源格式。</p><ol><li><p>加载数据 scala val df = spark.read.load(&quot;examples/src/main/resources/users.parquet&quot;) scala df.show</p></li><li><p>保存数据 scala var df = spark.read.json(&quot;/opt/module/data/input/people.json&quot;) //保存为 parquet 格式 scala df.write.mode(&quot;append&quot;).save(&quot;/opt/module/data/output&quot;)</p></li></ol><h3 id="_2-8-3-json" tabindex="-1"><a class="header-anchor" href="#_2-8-3-json"><span>2.8.3 JSON</span></a></h3><p>​ Spark SQL 能够自动推测 JSON 数据集的结构，并将它加载为一个 Dataset[Row]. 可以通过 SparkSession.read.json()去加载 JSON 文件。 注意：Spark 读取的 JSON 文件不是传统的 JSON 文件，<strong>每一行都应该是一个 JSON 串</strong>。格式如下： {&quot;name&quot;:&quot;Michael&quot;} {&quot;name&quot;:&quot;Andy&quot;， &quot;age&quot;:30} [{&quot;name&quot;:&quot;Justin&quot;， &quot;age&quot;:19},{&quot;name&quot;:&quot;Justin&quot;， &quot;age&quot;:19}] 1）导入隐式转换 import spark.implicits._ 2）加载 JSON 文件 val path = &quot;/opt/module/spark-local/people.json&quot; val peopleDF = spark.read.json(path) 3）创建临时表 peopleDF.createOrReplaceTempView(&quot;people&quot;) 4）数据查询 val teenagerNamesDF = spark.sql(&quot;SELECT name FROM people WHERE age BETWEEN 13 AND 19&quot;) teenagerNamesDF.show() +------+ | name| +------+ |Justin| +------+</p><h3 id="_2-8-4-csv" tabindex="-1"><a class="header-anchor" href="#_2-8-4-csv"><span>2.8.4 CSV</span></a></h3><p>​ Spark SQL 可以配置 CSV 文件的列表信息，读取 CSV 文件,CSV 文件的第一行设置为数据列</p><p>spark.read.format(&quot;csv&quot;).option(&quot;sep&quot;, &quot;;&quot;).option(&quot;inferSchema&quot;, &quot;true&quot;).option(&quot;header&quot;, &quot;true&quot;).load(&quot;data/user.csv&quot;)</p><h3 id="_2-8-5-mysql" tabindex="-1"><a class="header-anchor" href="#_2-8-5-mysql"><span>2.8.5 MySQL</span></a></h3><p>​ Spark SQL 可以通过 JDBC 从关系型数据库中读取数据的方式创建 DataFrame，通过对DataFrame 一系列的计算后，还可以将数据再写回关系型数据库中。如果使用 spark-shell 操作，可在启动 shell 时指定相关的数据库驱动路径或者将相关的数据库驱动放到 spark 的类路径下。 bin/spark-shell --jars mysql-connector-java-5.1.27-bin.jar 我们这里只演示在 Idea 中通过 JDBC 对 Mysql 进行操作 1）导入依赖</p><div class="language-xml line-numbers-mode" data-highlighter="prismjs" data-ext="xml"><pre><code><span class="line">&lt;dependency</span>
<span class="line"> &lt;groupIdmysql&lt;/groupId</span>
<span class="line"> &lt;artifactIdmysql-connector-java&lt;/artifactId</span>
<span class="line"> &lt;version5.1.27&lt;/version</span>
<span class="line">&lt;/dependency</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2）读取数据</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> </span>
<span class="line">SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;SparkSQL&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//创建 SparkSession 对象</span></span>
<span class="line"><span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</span>
<span class="line"><span class="token comment">//方式 1：通用的 load 方法读取</span></span>
<span class="line">spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;driver&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;com.mysql.jdbc.Driver&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123123&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show</span>
<span class="line"></span>
<span class="line"><span class="token comment">//方式 2:通用的 load 方法读取 参数另一种形式</span></span>
<span class="line">spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>options<span class="token punctuation">(</span>Map<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token operator">-</span><span class="token string">&quot;jdbc:mysql://linux1:3306/spark-sql?user=root&amp;password=123123&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;dbtable&quot;</span><span class="token operator">-</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;driver&quot;</span><span class="token operator">-</span><span class="token string">&quot;com.mysql.jdbc.Driver&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show</span>
<span class="line"><span class="token comment">//方式 3:使用 jdbc 方法读取</span></span>
<span class="line"><span class="token keyword">val</span> props<span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span></span>
<span class="line">props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123123&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">val</span> df<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span></span>
<span class="line">df<span class="token punctuation">.</span>show</span>
<span class="line"><span class="token comment">//释放资源</span></span>
<span class="line">spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>3）写入数据</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token keyword">case</span> <span class="token keyword">class</span> User2<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span></span>
<span class="line">。。。</span>
<span class="line"><span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> </span>
<span class="line">SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;SparkSQL&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//创建 SparkSession 对象</span></span>
<span class="line"><span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</span>
<span class="line"><span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>User2<span class="token punctuation">]</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span>User2<span class="token punctuation">(</span><span class="token string">&quot;lisi&quot;</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> </span>
<span class="line">User2<span class="token punctuation">(</span><span class="token string">&quot;zs&quot;</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">val</span> ds<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>User2<span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDS</span>
<span class="line"><span class="token comment">//方式 1：通用的方式 format 指定写出类型</span></span>
<span class="line">ds<span class="token punctuation">.</span>write</span>
<span class="line"> <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123123&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Append<span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//方式 2：通过 jdbc 方法</span></span>
<span class="line"><span class="token keyword">val</span> props<span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span></span>
<span class="line">props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123123&quot;</span><span class="token punctuation">)</span></span>
<span class="line">ds<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Append<span class="token punctuation">)</span><span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://linux1:3306/spark-sql&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment">//释放资源</span></span>
<span class="line">spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-8-6-hive" tabindex="-1"><a class="header-anchor" href="#_2-8-6-hive"><span>2.8.6 Hive</span></a></h3><p>​ Apache Hive 是 Hadoop 上的 SQL 引擎，Spark SQL 编译时可以包含 Hive 支持，也可以不包含。包含 Hive 支持的 Spark SQL 可以支持 Hive 表访问、UDF (用户自定义函数)以及 Hive 查询语言(HiveQL/HQL)等。需要强调的一点是，如果要在 Spark SQL 中包含Hive 的库，并不需要事先安装 Hive。一般来说，最好还是在编译 Spark SQL 时引入 Hive支持，这样就可以使用这些特性了。如果你下载的是二进制版本的 Spark，它应该已经在编译时添加了 Hive 支持。若要把 Spark SQL 连接到一个部署好的 Hive 上，你必须把 <code>hive-site.xml</code> 复制到Spark 的配置文件目录中($SPARK_HOME/conf)。即使没有部署好 Hive，Spark SQL 也可以运行。 需要注意的是，如果你没有部署好 Hive，Spark SQL 会在当前的工作目录中创建出自己的 Hive 元数据仓库，叫作 metastore_db。此外，如果你尝试使用 HiveQL 中的CREATE TABLE (并非 CREATE EXTERNAL TABLE)语句来创建表，这些表会被放在你默认的文件系统中的 /user/hive/warehouse 目录中(如果你的 classpath 中有配好的hdfs-site.xml，默认的文件系统就是 HDFS，否则就是本地文件系统)。spark-shell 默认是 Hive 支持的；代码中是默认不支持的，需要手动指定（加一个参数即可）。</p><p>1）内嵌的 HIVE 如果使用 Spark 内嵌的 Hive, 则什么都不用做, 直接使用即可.Hive 的元数据存储在 derby 中, 默认仓库地址:$SPARK_HOME/spark-warehouse</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;show tables&quot;</span><span class="token punctuation">)</span>.show</span>
<span class="line">+--------+---------+-----------+</span>
<span class="line"><span class="token operator">|</span>database<span class="token operator">|</span>tableName<span class="token operator">|</span>isTemporary<span class="token operator">|</span></span>
<span class="line">+--------+---------+-----------+ +--------+---------+-----------+</span>
<span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;create table aa(id int)&quot;</span><span class="token punctuation">)</span></span>
<span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;show tables&quot;</span><span class="token punctuation">)</span>.show</span>
<span class="line">+--------+---------+-----------+</span>
<span class="line"><span class="token operator">|</span>database<span class="token operator">|</span>tableName<span class="token operator">|</span>isTemporary<span class="token operator">|</span></span>
<span class="line">+--------+---------+-----------+</span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> aa<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line">+--------+---------+-----------+</span>
<span class="line"><span class="token comment"># 向表加载本地数据</span></span>
<span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;load data local inpath &#39;input/ids.txt&#39; into table aa&quot;</span><span class="token punctuation">)</span></span>
<span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;select * from aa&quot;</span><span class="token punctuation">)</span>.show</span>
<span class="line">+---+</span>
<span class="line"><span class="token operator">|</span> <span class="token function">id</span><span class="token operator">|</span></span>
<span class="line">+---+</span>
<span class="line"><span class="token operator">|</span> <span class="token number">1</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">2</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">3</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> <span class="token number">4</span><span class="token operator">|</span></span>
<span class="line">+---+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在实际使用中, 几乎没有任何人会使用内置的 Hive 2）外部的 HIVE 如果想连接外部已经部署好的 Hive，需要通过以下几个步骤：</p><ul><li>Spark 要接管 Hive 需要把 hive-site.xml 拷贝到 conf/目录下</li><li>把 Mysql 的驱动 copy 到 jars/目录下</li><li>如果访问不到 hdfs，则需要把 core-site.xml 和 hdfs-site.xml 拷贝到 conf/目录下</li><li>重启 spark-shell</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line">scala spark.sql<span class="token punctuation">(</span><span class="token string">&quot;show tables&quot;</span><span class="token punctuation">)</span>.show</span>
<span class="line"><span class="token number">20</span>/04/25 <span class="token number">22</span>:05:14 WARN ObjectStore: Failed to get database global_temp, returning </span>
<span class="line">NoSuchObjectException</span>
<span class="line">+--------+--------------------+-----------+</span>
<span class="line"><span class="token operator">|</span>database<span class="token operator">|</span> tableName<span class="token operator">|</span>isTemporary<span class="token operator">|</span></span>
<span class="line">+--------+--------------------+-----------+</span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> emp<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span>hive_hbase_emp_table<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> relevance_hbase_emp<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> staff_hive<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> ttt<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line"><span class="token operator">|</span> default<span class="token operator">|</span> user_visit_action<span class="token operator">|</span> <span class="token boolean">false</span><span class="token operator">|</span></span>
<span class="line">+--------+--------------------+-----------+</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>3）运行 Spark SQL CLI Spark SQL CLI 可以很方便的在本地运行 Hive 元数据服务以及从命令行执行查询任务。在Spark 目录下执行如下命令启动 Spark SQL CLI，直接执行 SQL 语句，类似一 Hive 窗口bin/spark-sql</p><p>4）运行 Spark beeline Spark Thrift Server 是 Spark 社区基于 HiveServer2 实现的一个 Thrift 服务。旨在无缝兼容HiveServer2。因为 Spark Thrift Server 的接口和协议都和 HiveServer2 完全一致，因此我们部署好 Spark Thrift Server 后，可以直接使用 hive 的 beeline 访问 Spark Thrift Server 执行相关语句。Spark Thrift Server 的目的也只是取代 HiveServer2，因此它依旧可以和 Hive Metastore进行交互，获取到 hive 的元数据。如果想连接 Thrift Server，需要通过以下几个步骤：</p><ul><li>Spark 要接管 Hive 需要把 hive-site.xml 拷贝到 conf/目录下</li><li>把 Mysql 的驱动 copy 到 jars/目录下</li><li>如果访问不到 hdfs，则需要把 core-site.xml 和 hdfs-site.xml 拷贝到 conf/目录下</li><li>启动 Thrift Serversbin/start-thriftserver.sh</li><li>使用 beeline 连接 Thrift Server bin/beeline -u jdbc:hive2://linux1:10000 -n root</li></ul><p>5）代码操作 Hive 1）导入依赖</p><div class="language-xml line-numbers-mode" data-highlighter="prismjs" data-ext="xml"><pre><code><span class="line">&lt;dependency</span>
<span class="line"> &lt;groupIdorg.apache.spark&lt;/groupId</span>
<span class="line"> &lt;artifactIdspark-hive_2.12&lt;/artifactId</span>
<span class="line"> &lt;version3.0.0&lt;/version</span>
<span class="line">&lt;/dependency</span>
<span class="line">&lt;dependency</span>
<span class="line"> &lt;groupIdorg.apache.hive&lt;/groupId</span>
<span class="line"> &lt;artifactIdhive-exec&lt;/artifactId</span>
<span class="line"> &lt;version1.2.1&lt;/version</span>
<span class="line">&lt;/dependency</span>
<span class="line">&lt;dependency</span>
<span class="line"> &lt;groupIdmysql&lt;/groupId</span>
<span class="line"> &lt;artifactIdmysql-connector-java&lt;/artifactId</span>
<span class="line"> &lt;version5.1.27&lt;/version</span>
<span class="line">&lt;/dependency</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2）将 hive-site.xml 文件拷贝到项目的 resources 目录中，代码实现</p><div class="language-scala line-numbers-mode" data-highlighter="prismjs" data-ext="scala"><pre><code><span class="line"><span class="token comment">//创建 SparkSession</span></span>
<span class="line"><span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession</span>
<span class="line"> <span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;sql&quot;</span><span class="token punctuation">)</span></span>
<span class="line"> <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：在开发工具中创建数据库默认是在本地仓库，通过参数修改数据库仓库的地址: <code>config(&quot;spark.sql.warehouse.dir&quot;, &quot;hdfs://linux1:8020/user/hive/warehouse&quot;)</code> 如果在执行操作时，出现如下错误：可以代码最前面增加如下代码解决： <code>System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;root&quot;)</code>此处的 root 改为你们自己的 hadoop 用户名称</p><h1 id="第3章-sparksql-项目实战" tabindex="-1"><a class="header-anchor" href="#第3章-sparksql-项目实战"><span>第3章 SparkSQL 项目实战</span></a></h1><h2 id="_3-1-数据准备" tabindex="-1"><a class="header-anchor" href="#_3-1-数据准备"><span>3.1 数据准备</span></a></h2><p>我们这次 Spark-sql 操作中所有的数据均来自 Hive，首先在 Hive 中创建表,，并导入数据。 一共有 3 张表： 1 张用户行为表，1 张城市表，1 张产品表</p><div class="language-sql line-numbers-mode" data-highlighter="prismjs" data-ext="sql"><pre><code><span class="line"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>user_visit_action<span class="token punctuation">`</span></span><span class="token punctuation">(</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>date<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>user_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>session_id<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>page_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>action_time<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>search_keyword<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>click_category_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>click_product_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>order_category_ids<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>order_product_ids<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>pay_category_ids<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>pay_product_ids<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>city_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&#39;\t&#39;</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">&#39;input/user_visit_action.txt&#39;</span> <span class="token keyword">into</span> <span class="token keyword">table</span> </span>
<span class="line">user_visit_action<span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>product_info<span class="token punctuation">`</span></span><span class="token punctuation">(</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>product_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>product_name<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>extend_info<span class="token punctuation">`</span></span> string<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&#39;\t&#39;</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">&#39;input/product_info.txt&#39;</span> <span class="token keyword">into</span> <span class="token keyword">table</span> product_info<span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>city_info<span class="token punctuation">`</span></span><span class="token punctuation">(</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>city_id<span class="token punctuation">`</span></span> <span class="token keyword">bigint</span><span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>city_name<span class="token punctuation">`</span></span> string<span class="token punctuation">,</span></span>
<span class="line"> <span class="token identifier"><span class="token punctuation">`</span>area<span class="token punctuation">`</span></span> string<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&#39;\t&#39;</span><span class="token punctuation">;</span></span>
<span class="line"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">&#39;input/city_info.txt&#39;</span> <span class="token keyword">into</span> <span class="token keyword">table</span> city_info<span class="token punctuation">;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-2-需求-各区域热门商品-top3" tabindex="-1"><a class="header-anchor" href="#_3-2-需求-各区域热门商品-top3"><span>3.2 需求：各区域热门商品 Top3</span></a></h2><h3 id="_3-2-1-需求简介" tabindex="-1"><a class="header-anchor" href="#_3-2-1-需求简介"><span>3.2.1 需求简介</span></a></h3><p>这里的热门商品是从点击量的维度来看的，计算各个区域前三大热门商品，并备注上每个商品在主要城市中的分布比例，超过两个城市用其他显示。 例如：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code><span class="line">地区 商品名称 点击次数 城市备注</span>
<span class="line">华北 商品 A 100000 北京 21.2%，天津 13.2%，其他 65.6%</span>
<span class="line">华北 商品 P 80200 北京 63.0%，太原 10%，其他 27.0%</span>
<span class="line">华北 商品 M 40000 北京 63.0%，太原 10%，其他 27.0%</span>
<span class="line">东北 商品 J 92000 大连 28%，辽宁 17.0%，其他 55.0%</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-2-2-需求分析" tabindex="-1"><a class="header-anchor" href="#_3-2-2-需求分析"><span>3.2.2 需求分析</span></a></h3><ul><li>查询出来所有的点击记录，并与 city_info 表连接，得到每个城市所在的地区，与Product_info 表连接得到产品名称</li><li>按照地区和商品 id 分组，统计出每个商品在每个地区的总点击次数</li><li>每个地区内按照点击次数降序排列</li><li>只取前三名</li><li>城市备注需要自定义 UDAF 函数</li></ul><h3 id="_3-2-3-功能实现" tabindex="-1"><a class="header-anchor" href="#_3-2-3-功能实现"><span>3.2.3 功能实现</span></a></h3><ul><li>连接三张表的数据，获取完整的数据（只有点击）</li><li>将数据根据地区，商品名称分组</li><li>统计商品点击次数总和,取 Top3</li><li>实现自定义聚合函数显示备注</li></ul></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">最近更新：: </span><time class="meta-item-info" datetime="2025-04-18T12:37:54.000Z" data-allow-mismatch>2025/4/18 12:37</time></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 921757697@qq.com">alice</span><!----><!--]--><!--]--></span></div></div></footer><!----><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/simple-doc/assets/app-CNZ6fT6P.js" defer></script>
  </body>
</html>
